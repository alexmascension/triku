{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up\n",
    "\n",
    "In this notebook we will prepare the necessary files to run the notebooks.\n",
    "\n",
    "We will set up the directories and download files automatically, if possible, to make this first process less tedious. Unfortunately, there will be some files that will need to be downloaded manually, either because the repository doesn't allow direct download, or because it requires some logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from vpolo.alevin import parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.getcwd() + '/code')\n",
    "\n",
    "# Selection of palettes for cluster coloring, and scatter values\n",
    "from triku_nb_code.file_download_and_generation import process_ding, process_mereu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = !pwd\n",
    "root_dir = root_dir[0][:-9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the data\n",
    "\n",
    "The data in this notebook is fundamental. We will download several datasets to do the benchamarkings, and we will also process them.\n",
    "\n",
    "Currently, if you have downloaded triku repo files directly, the file structure should be as follows:\n",
    "```\n",
    "triku\\\n",
    "    cli\\\n",
    "    pp\\\n",
    "    ...\n",
    "notebooks\\\n",
    "    code\\\n",
    "    *.ipynb files\n",
    "LICENSE\n",
    "MANIFEST.in\n",
    "README.md\n",
    "requirements.txt\n",
    "setup.py\n",
    "```\n",
    "\n",
    "After this part we will add a `data` folder, with some datasets.\n",
    "That is, at the end of the section you should have a structure like this:\n",
    "\n",
    "```\n",
    "data\\\n",
    "triku\\\n",
    "notebooks\\\n",
    "LICENSE\n",
    "...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading Mereu et al. 2020 dataset\n",
    "This is a great benchmarking dataset with human PBMCs and mouse colon cells, with several library preparation methods. We will download some of them, mainly the mose used ones (Chromium, SMARTseq-2, CELseq, InDrops, etc.).\n",
    "\n",
    "We will also include cell type information for each dataset, so that we can use it later to do comparisons with other methods.\n",
    "\n",
    "\n",
    "The final structure of the folder should be:\n",
    "```\n",
    "data\\\n",
    "    Mereu_2020\\\n",
    "        tsv\\\n",
    "        cell_types\\\n",
    "```\n",
    "\n",
    "* `tsv` should have the original .tsv files from GEO reposititory.\n",
    "* `cell_types` should have two dataframes, one for human and one for mouse. This dataframes have the cell types depicted in the publication.\n",
    "   The cell types have been obtained from [here](https://www.dropbox.com/s/i8mwmyymchx8mn8/sce.all_classified.technologies.RData?dl=0). For simplicity, they have been extracted from the adata, and added into the folder.\n",
    "* `Mereu_2020` should have several adatas, for each tecnique and organism, with read counts and the observed cell types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mereu_dir = root_dir + 'data/Mereu_2020/'\n",
    "os.makedirs(mereu_dir + 'tsv', exist_ok=True)\n",
    "os.makedirs(mereu_dir + 'cell_types', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mereu_tsv_dir = mereu_dir + 'tsv'\n",
    "# CELseq2\n",
    "!aria2c -x 16 https://ftp.ncbi.nlm.nih.gov/geo/series/GSE133nnn/GSE133539/suppl/GSE133539%5FCELseq2%5Fhuman%5Fexp%5Fmat%2Etsv%2Egz -d $mereu_tsv_dir\n",
    "!aria2c -x 16 https://ftp.ncbi.nlm.nih.gov/geo/series/GSE133nnn/GSE133539/suppl/GSE133539%5FCELseq2%5Fmouse%5Fexp%5Fmat%2Etsv%2Egz -d $mereu_tsv_dir\n",
    "# Droposeq\n",
    "!aria2c -x 16 https://ftp.ncbi.nlm.nih.gov/geo/series/GSE133nnn/GSE133540/suppl/GSE133540%5FDropseq%5Fhuman%5Fexp%5Fmat%2Etsv%2Egz -d $mereu_tsv_dir\n",
    "!aria2c -x 16 https://ftp.ncbi.nlm.nih.gov/geo/series/GSE133nnn/GSE133540/suppl/GSE133540%5FDropseq%5Fmouse%5Fexp%5Fmat%2Etsv%2Egz -d $mereu_tsv_dir\n",
    "# QUARTZseq\n",
    "!aria2c -x 16 https://ftp.ncbi.nlm.nih.gov/geo/series/GSE133nnn/GSE133543/suppl/GSE133543%5FQUARTZseq%5Fhuman%5Fexp%5Fmat%2Etsv%2Egz -d $mereu_tsv_dir\n",
    "!aria2c -x 16 https://ftp.ncbi.nlm.nih.gov/geo/series/GSE133nnn/GSE133543/suppl/GSE133543%5FQUARTZseq%5Fmouse%5Fexp%5Fmat%2Etsv%2Egz -d $mereu_tsv_dir\n",
    "# SMARTseq2\n",
    "!aria2c -x 16 https://ftp.ncbi.nlm.nih.gov/geo/series/GSE133nnn/GSE133545/suppl/GSE133545%5FSMARTseq2%5Fhuman%5Fexp%5Fmat%2Etsv%2Egz -d $mereu_tsv_dir\n",
    "!aria2c -x 16 https://ftp.ncbi.nlm.nih.gov/geo/series/GSE133nnn/GSE133545/suppl/GSE133545%5FSMARTseq2%5Fmouse%5Fexp%5Fmat%2Etsv%2Egz -d $mereu_tsv_dir\n",
    "# singleNuclei\n",
    "!aria2c -x 16 https://ftp.ncbi.nlm.nih.gov/geo/series/GSE133nnn/GSE133546/suppl/GSE133546%5FSingleNuclei%5Fhuman%5Fexp%5Fmat%2Etsv%2Egz -d $mereu_tsv_dir\n",
    "!aria2c -x 16 https://ftp.ncbi.nlm.nih.gov/geo/series/GSE133nnn/GSE133546/suppl/GSE133546%5FSingleNuclei%5Fmouse%5Fexp%5Fmat%2Etsv%2Egz -d $mereu_tsv_dir\n",
    "# ddSEQ\n",
    "!aria2c -x 16 https://ftp.ncbi.nlm.nih.gov/geo/series/GSE133nnn/GSE133547/suppl/GSE133547%5FddSEQ%5Fhuman%5Fexp%5Fmat%2Etsv%2Egz -d $mereu_tsv_dir\n",
    "!aria2c -x 16 https://ftp.ncbi.nlm.nih.gov/geo/series/GSE133nnn/GSE133547/suppl/GSE133547%5FddSEQ%5Fmouse%5Fexp%5Fmat%2Etsv%2Egz -d $mereu_tsv_dir\n",
    "# inDrop\n",
    "!aria2c -x 16 https://ftp.ncbi.nlm.nih.gov/geo/series/GSE133nnn/GSE133548/suppl/GSE133548%5FinDrop%5Fhuman%5Fexp%5Fmat%2Etsv%2Egz -d $mereu_tsv_dir\n",
    "!aria2c -x 16 https://ftp.ncbi.nlm.nih.gov/geo/series/GSE133nnn/GSE133548/suppl/GSE133548%5FinDrop%5Fmouse%5Fexp%5Fmat%2Etsv%2Egz -d $mereu_tsv_dir\n",
    "# 10X\n",
    "!aria2c -x 16 https://ftp.ncbi.nlm.nih.gov/geo/series/GSE133nnn/GSE133535/suppl/GSE133535%5F10X2x5Kcell250Kreads%5Fhuman%5Fexp%5Fmat%2Etsv%2Egz -d $mereu_tsv_dir\n",
    "!aria2c -x 16 https://ftp.ncbi.nlm.nih.gov/geo/series/GSE133nnn/GSE133535/suppl/GSE133535%5F10X2x5Kcell250Kreads%5Fmouse%5Fexp%5Fmat%2Etsv%2Egz -d $mereu_tsv_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gunzip $mereu_tsv_dir/*.gz "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that files have been downloaded and extracted, we will generate the adatas. Each adata will have the structure `{technique}_{organism}.h5`. \n",
    "It will contain the cells that are annotated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_mereu(mereu_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading Ding et al. 2020 dataset\n",
    "Ding dataset is uploaded to Single Cell Portal, under sccesion numbers SCP424 and SCP425. The data is under login accession, so you must login, download the data, and place it in the listed directories.\n",
    "\n",
    "Adter dataset downloading the final file structure should look like this:\n",
    "```\n",
    "Ding_2020\\\n",
    "    human\\\n",
    "        cells.read.new.txt   ->   Barcode names\n",
    "        counts.read.txt.gz   ->   Count matrix in MM format\n",
    "        genes.read.txt       ->   Feature names\n",
    "        meta.txt             ->   Metadata file with annotations\n",
    "    mouse\\\n",
    "        cells.names.new.txt  ->   Barcode names\n",
    "        count.reads.txt.gz   ->   Count matrix in MM format\n",
    "        genes.count.txt      ->   Feature names\n",
    "        meta_combined.txt    ->   Metadata file with annotations\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ding_dir = root_dir + 'data/Ding_2020/'\n",
    "os.makedirs(ding_dir + 'human', exist_ok=True)\n",
    "os.makedirs(ding_dir + 'mouse', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_ding(ding_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify nomenclature with Mereu's dataset, we are going to delete and rename certain datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.replace(ding_dir + '/10x Chromium (v3)_human.h5ad', ding_dir + '/10X_human.h5ad')\n",
    "os.replace(ding_dir + '/10x Chromium_mouse.h5ad', ding_dir + '/10X_mouse.h5ad')\n",
    "os.replace(ding_dir + '/DroNc-seq_mouse.h5ad', ding_dir + '/SingleNuclei_human.h5ad')\n",
    "os.replace(ding_dir + '/inDrops_human.h5ad', ding_dir + '/inDrop_human.h5ad')\n",
    "os.replace(ding_dir + '/Drop-seq_human.h5ad', ding_dir + '/Dropseq_human.h5ad')\n",
    "os.replace(ding_dir + '/Smart-seq2_human.h5ad', ding_dir + '/SMARTseq2_human.h5ad')\n",
    "os.replace(ding_dir + '/Smart-seq2_mouse.h5ad', ding_dir + '/SMARTseq2_mouse.h5ad')\n",
    "os.replace(ding_dir + '/CEL-Seq2_human.h5ad', ding_dir + '/CELseq2_human.h5ad')\n",
    "os.remove(ding_dir + '/10x Chromium (v2) A_human.h5ad')\n",
    "os.remove(ding_dir + '/10x Chromium (v2) B_human.h5ad')\n",
    "os.remove(ding_dir + '/10x Chromium (v2)_human.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading 10X datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://cf.10xgenomics.com/samples/cell-exp/3.0.0/heart_10k_v3/heart_10k_v3_raw_feature_bc_matrix.h5 -P $root_dir/data/10x\n",
    "!wget http://cf.10xgenomics.com/samples/cell-exp/3.0.0/neuron_10k_v3/neuron_10k_v3_raw_feature_bc_matrix.h5 -P $root_dir/data/10x\n",
    "!wget http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_10k_v3/pbmc_10k_v3_raw_feature_bc_matrix.h5 -P $root_dir/data/10x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!aria2c -x 8 http://s3-us-west-2.amazonaws.com/10x.files/samples/cell-exp/3.0.0/neuron_10k_v3/neuron_10k_v3_fastqs.tar -d $root_dir/data/10x/FASTQs\n",
    "!aria2c -x 8 http://s3-us-west-2.amazonaws.com/10x.files/samples/cell-exp/3.0.0/heart_10k_v3/heart_10k_v3_fastqs.tar -d $root_dir/data/10x/FASTQs\n",
    "!aria2c -x 8 http://s3-us-west-2.amazonaws.com/10x.files/samples/cell-exp/3.0.0/pbmc_10k_v3/pbmc_10k_v3_fastqs.tar -d $root_dir/data/10x/FASTQs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xvf $root_dir/data/10x/FASTQs/neuron_10k_v3_fastqs.tar -C $root_dir/data/10x/FASTQs/\n",
    "!tar -xvf $root_dir/data/10x/FASTQs/heart_10k_v3_fastqs.tar -C $root_dir/data/10x/FASTQs/\n",
    "!tar -xvf $root_dir/data/10x/FASTQs/pbmc_10k_v3_fastqs.tar -C $root_dir/data/10x/FASTQs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aria2c -x 16 ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M25/gencode.vM25.pc_transcripts.fa.gz -d $root_dir/data/references\n",
    "!aria2c -x 16 ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M25/gencode.vM25.primary_assembly.annotation.gtf.gz -d $root_dir/data/references\n",
    "    \n",
    "!aria2c -x 16 ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_34/gencode.v34.pc_transcripts.fa.gz -d $root_dir/data/references\n",
    "!aria2c -x 16 ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_34/gencode.v34.primary_assembly.annotation.gtf.gz -d $root_dir/data/references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prefix in ['vM25', 'v34']:\n",
    "    with gzip.open(f'{root_dir}/data/references/gencode.{prefix}.pc_transcripts.fa.gz', 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    t2gdict = {}\n",
    "    for i, line in enumerate(lines):\n",
    "        line = line.decode('utf-8')\n",
    "        if line.startswith('>'):\n",
    "            t = line.split('|')[0]\n",
    "            t2gdict[f'{t[1:]}'] = line.split('|')[5]\n",
    "            lines[i] = t + '\\n'\n",
    "        else:\n",
    "            lines[i] = line\n",
    "\n",
    "    df = pd.DataFrame(t2gdict.items())\n",
    "    df.to_csv(f'{root_dir}/data/references/txp2gene_{prefix}.tsv', sep='\\t', header=None, index=None)\n",
    "\n",
    "    with open(f'{root_dir}/data/references/gencode.{prefix}.pc_transcripts.fa', 'w') as f:\n",
    "        f.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!salmon index -t $root_dir/data/references/gencode.vM25.pc_transcripts.fa -i $root_dir/data/references/index_mouse\n",
    "!salmon index -t $root_dir/data/references/gencode.v34.pc_transcripts.fa -i $root_dir/data/references/index_human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!salmon alevin -lISR -1 $root_dir/data/10x/FASTQs/neuron_10k_v3_fastqs/neuron_10k_v3_S1_L001_R1_001.fastq.gz \\\n",
    "$root_dir/data/10x/FASTQs/neuron_10k_v3_fastqs/neuron_10k_v3_S1_L002_R1_001.fastq.gz \\\n",
    "-2 $root_dir/data/10x/FASTQs/neuron_10k_v3_fastqs/neuron_10k_v3_S1_L001_R2_001.fastq.gz \\\n",
    "$root_dir/data/10x/FASTQs/neuron_10k_v3_fastqs/neuron_10k_v3_S1_L002_R2_001.fastq.gz \\\n",
    "--chromium -i $root_dir/data/references/index_mouse -p 8 -o $root_dir/data/10x/FASTQs/alevin_output_neuron --tgMap $root_dir/data/references/txp2gene_vM25.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!salmon alevin -lISR -1 $root_dir/data/10x/FASTQs/heart_10k_v3_fastqs/heart_10k_v3_S1_L001_R1_001.fastq.gz \\\n",
    "$root_dir/data/10x/FASTQs/heart_10k_v3_fastqs/heart_10k_v3_S1_L002_R1_001.fastq.gz \\\n",
    "-2 $root_dir/data/10x/FASTQs/heart_10k_v3_fastqs/heart_10k_v3_S1_L001_R2_001.fastq.gz \\\n",
    "$root_dir/data/10x/FASTQs/heart_10k_v3_fastqs/heart_10k_v3_S1_L002_R2_001.fastq.gz \\\n",
    "--chromium -i $root_dir/data/references/index_mouse -p 8 -o $root_dir/data/10x/FASTQs/alevin_output_heart --tgMap $root_dir/data/references/txp2gene_vM25.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!salmon alevin -lISR -1 $root_dir/data/10x/FASTQs/pbmc_10k_v3_fastqs/pbmc_10k_v3_S1_L001_R1_001.fastq.gz \\\n",
    "$root_dir/data/10x/FASTQs/pbmc_10k_v3_fastqs/pbmc_10k_v3_S1_L002_R1_001.fastq.gz \\\n",
    "-2 $root_dir/data/10x/FASTQs/pbmc_10k_v3_fastqs/pbmc_10k_v3_S1_L001_R2_001.fastq.gz \\\n",
    "$root_dir/data/10x/FASTQs/pbmc_10k_v3_fastqs/pbmc_10k_v3_S1_L002_R2_001.fastq.gz \\\n",
    "--chromium -i $root_dir/data/references/index_human -p 8 -o $root_dir/data/10x/FASTQs/alevin_output_pbmc --tgMap $root_dir/data/references/txp2gene_v34.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_prefix in ['heart', 'pbmc', 'neuron']:\n",
    "    alevin_df = parser.read_quants_bin(f\"{root_dir}/data/10x/FASTQs/alevin_output_{dataset_prefix}\")\n",
    "    adata = sc.AnnData(alevin_df)\n",
    "    adata.write_h5ad(f\"{root_dir}/data/10x/FASTQs/alevin_output_{dataset_prefix}/{dataset_prefix}_10k_v3_filtered_feature_bc_matrix.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating artificial datasets\n",
    "Refer to `2_Generation_of_artificial_datasets.ipynb` notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:alex-salmon]",
   "language": "python",
   "name": "conda-env-alex-salmon-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
