{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro \n",
    "\n",
    "In this notebook we will build, step by step, the background to use the Earth Mover Distance (EMD), also known as Wasserstein distance, to evaluate the the differences of distribution of genes with expression in their nearest neighbors. This method will allow us to select the genes whose expression patterns are gathered in a subset of cells, which we can intuitively assign as an *interesting* gene. In the opposite direction, we will avoid genes with a constant expression in many cells, without any pattern, since that gene will not provide any information about cell types or cell states.\n",
    "\n",
    "The notebook will be divided in several parts. First, we will explain the rationale for using the kNN, and how it is computed. For that we will use a randomized dataset, which contains the same number of reads (and zeros, if required) per cell, but whose reads have been distributed randomly. The random distribution of reads within the selected cells follows a binomial distribution. \n",
    "\n",
    "Second, we will infer which is the distribution in the kNN cells (we consider the kNN cells of cells which already have some expression). We will come to the conclusion that the convolution of the distribution of reads distribution is indeed the best fitting distribution (convolution is explained later on in the notebook). \n",
    "\n",
    "Third, we will apply the fitting of distributions and their convolutions to biological datasets.\n",
    "To assess the difference between the two distributions we will use the Earth Mover Distance (EMD), also known as Wasserstein distance. There are many functions to evaluate difference between two distributions, like doing a Kolmogorov-Smirnov test, Kullback-Leiber distance, distribution absolute difference, Jensen-Shannon divergence, etc. The choice of EMD is, first, because of its simple and practical interpretation: EMD can be interpreted as the minimum *effort* to transform one distribution into the other. Second, it has been found that EMD performs best compared to other distribution comparison distances. Third, there are meny implementations of the EMD in python, which have significantly increased the time performance for EMD calculation.\n",
    "\n",
    "* http://robotics.stanford.edu/~rubner/papers/rubnerIjcv00.pdf\n",
    "* https://hal.archives-ouvertes.fr/hal-01984970/document\n",
    "\n",
    "Instead of using EMD as such, we will apply a modification that will allow us to compare the distances with genes of different mean expresion values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T12:01:12.111527Z",
     "start_time": "2020-02-08T12:01:09.165623Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports here\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import scipy.stats as sts\n",
    "import scipy.optimize as opt\n",
    "import pandas as pd\n",
    "import triku as tk\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib \n",
    "import matplotlib as mpl\n",
    "from numba import jit, njit\n",
    "import ray\n",
    "from tqdm.notebook import tqdm\n",
    "import scipy.signal as sgn\n",
    "from pyemd import emd\n",
    "\n",
    "import scanpy as sc\n",
    "\n",
    "# Especial imports\n",
    "from sklearn.decomposition import PCA\n",
    "from umap.umap_ import fuzzy_simplicial_set, nearest_neighbors\n",
    "\n",
    "# Parallel imports\n",
    "import ray\n",
    "\n",
    "\n",
    "random_state = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.logger.setLevel(logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from triku_nb_code.palettes_and_cmaps import magma, bold_and_vivid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T12:01:16.886724Z",
     "start_time": "2020-02-08T12:01:16.873950Z"
    }
   },
   "outputs": [],
   "source": [
    "from bokeh.io import show, output_notebook, reset_output\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models import Circle, ColumnDataSource, Div, Grid, Line, LinearAxis, Plot, Range1d, Legend, LinearColorMapper, BasicTicker, PrintfTickFormatter, ColorBar\n",
    "from bokeh.sampledata.unemployment1948 import data\n",
    "\n",
    "reset_output()\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    "These part here will include certain functions used throughout the notebook. Some of these functions have been optimized and adapted into triku's core."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to retrieve count distribution in the kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T12:01:17.394240Z",
     "start_time": "2020-02-08T12:01:17.381448Z"
    }
   },
   "outputs": [],
   "source": [
    "def return_knn_indices(array, knn=None, return_random=False):\n",
    "    if knn is None:\n",
    "        knn = int(0.5 * array.shape[0] ** 0.5)\n",
    "    pca = PCA(n_components=50, whiten=True, svd_solver='auto').fit_transform(array)\n",
    "    \n",
    "    if return_random:\n",
    "        knn_indices = np.zeros((array.shape[0], knn))\n",
    "        ran = np.arange(0, array.shape[0])\n",
    "        for i in tqdm(ran):\n",
    "            knn_indices[i, 1:] = np.random.choice(ran, knn-1, replace=False)\n",
    "            \n",
    "        knn_indices[:, 0] = np.arange(array.shape[0])            \n",
    "        \n",
    "    else:\n",
    "        knn_indices, knn_dists, forest = nearest_neighbors(pca, n_neighbors=knn, metric='cosine',\n",
    "                              random_state=np.random.RandomState(random_state), angular=False, metric_kwds={})\n",
    "    \n",
    "    \n",
    "    return knn_indices.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T12:01:17.569029Z",
     "start_time": "2020-02-08T12:01:17.560406Z"
    }
   },
   "outputs": [],
   "source": [
    "@njit\n",
    "def get_counts_knn(arr_counts_per_cell, knn):\n",
    "    counts = []\n",
    "    for i in np.where(arr_counts_per_cell > 0)[0]:\n",
    "        for trial in range(1):\n",
    "            choices = np.concatenate((np.arange(0, i), np.arange(i+1, len(arr_counts_per_cell))))\n",
    "            counts.append(np.sum(arr_counts_per_cell[np.random.choice(choices, knn-1, replace=False)]) +\n",
    "                         arr_counts_per_cell[i])\n",
    "       \n",
    "    return np.array(counts)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T12:01:17.895412Z",
     "start_time": "2020-02-08T12:01:17.877782Z"
    }
   },
   "outputs": [],
   "source": [
    "# @njit\n",
    "def numbaaa(X_gene, NN_cells_with_positive_expression):\n",
    "    return_list = []\n",
    "    for cell in range(len(NN_cells_with_positive_expression)):\n",
    "        return_list.append(X_gene[NN_cells_with_positive_expression[cell, :]].sum())\n",
    "   \n",
    "    return np.array(return_list)\n",
    "\n",
    "\n",
    "@ray.remote\n",
    "def return_expression_info_per_gene(gene_idx, adata_X, knn_indices, zero_counts, fill_zeros):\n",
    "    # Select the expression column for that gene\n",
    "    try:\n",
    "        arr_expr_gene = np.asarray(adata_X[:, gene_idx].todense()).flatten()\n",
    "    except:\n",
    "        arr_expr_gene = np.asarray(adata_X[:, gene_idx]).flatten()\n",
    "        \n",
    "    # Select, from that column, the cells (rows) that have positive expression\n",
    "    if zero_counts:\n",
    "        selected_cells = np.arange(len(adata_X))\n",
    "    else:\n",
    "        selected_cells = np.argwhere(arr_expr_gene > 0).flatten()\n",
    "   \n",
    "    # Get the NN matrix for the cells with positive expression. This matrix is of n_cells x kNN\n",
    "    NN_cells = knn_indices[selected_cells, :]\n",
    "   \n",
    "    # Apply a mask to select, from each cell, the neighbors that have positive expression\n",
    "    # Here, we include the cell from which the kNN are extracted\n",
    "    mask_neighbors_expressing = np.isin(NN_cells, selected_cells)[:, :]\n",
    "   \n",
    "    # Get the expression from the neighbors\n",
    "    expression_in_neighbors = numbaaa(arr_expr_gene, NN_cells)\n",
    "    \n",
    "    if fill_zeros:\n",
    "        expression_in_cells = np.zeros(adata_X.shape[0])\n",
    "        expression_in_cells[selected_cells] = expression_in_neighbors\n",
    "        return expression_in_cells\n",
    "    else:\n",
    "        return expression_in_neighbors\n",
    "\n",
    "\n",
    "def return_expression_info(list_genes, adata, knn_indices, category_name = 0, zero_counts=False, \n",
    "                           fill_zeros=False):\n",
    "    # This function returns a dictionary of genes: expression in kNN for gene, \n",
    "    # and also a dictionary of gene: category, where category is a number added by the user. This\n",
    "    # will come in handy for plotting certain figures with different categories.\n",
    "    dict_percentage_expressing_cells_kNN, dict_expression_per_kNN, dict_categories = {}, {}, {}\n",
    "   \n",
    "\n",
    "    list_idx_genes = [np.argwhere(adata.var_names == gene).flatten()[0] for gene in list_genes]\n",
    "    \n",
    "    ray.shutdown()\n",
    "    ray.init()\n",
    "    \n",
    "    adata_X_obj = ray.put(adata.X)\n",
    "    knn_indices_obj = ray.put(knn_indices)\n",
    "    \n",
    "    obj_ids_list = [return_expression_info_per_gene.remote(\n",
    "       gene_idx=list_idx_genes[i],\n",
    "       adata_X=adata_X_obj, \n",
    "       knn_indices=knn_indices_obj, \n",
    "       zero_counts=zero_counts, \n",
    "    fill_zeros=fill_zeros) for i in range(len(list_idx_genes))]\n",
    "    \n",
    "    obj_ids = ray.get(obj_ids_list)\n",
    "    \n",
    "    ray.shutdown()\n",
    "    \n",
    "    for i in range(len(obj_ids)):\n",
    "        dict_expression_per_kNN[list_genes[i]] = obj_ids[i]\n",
    "        dict_categories[list_genes[i]] = category_name\n",
    "    \n",
    "    \n",
    "    return dict_expression_per_kNN, dict_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to randomize the count matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T12:01:18.223994Z",
     "start_time": "2020-02-08T12:01:18.209241Z"
    }
   },
   "outputs": [],
   "source": [
    "def return_per_zeros(mu, phi):\n",
    "    # This formula is the expected proportion of zeros based on the mean (not log-transformed) and \n",
    "    # the variance. In realitym phi here should be 1/var, but it is easier to fit the inverse directly.\n",
    "    return (phi/(mu + phi))**phi\n",
    "\n",
    "\n",
    "def create_random_count_matrix(matrix=None, n_cells=1000, n_genes=1000, n_min_reads=None, n_max_reads=None,\n",
    "                               method='binomial', phi=0.35):\n",
    "    \"\"\"\n",
    "    The matrix should have Cells x Genes format.\n",
    "    \"\"\"\n",
    "\n",
    "    if matrix is not None:\n",
    "        n_reads_per_gene = matrix.sum(0).astype(int)\n",
    "        n_zeros = (matrix == 0).sum(0)\n",
    "        n_cells, n_genes = matrix.shape\n",
    "    else:\n",
    "        if n_max_reads is None: n_min_reads = int(n_cells * 0.2)\n",
    "        if n_max_reads is None: n_max_reads = n_cells * 7\n",
    "        n_reads_per_gene = np.linspace(n_min_reads, n_max_reads, n_genes, dtype=int)\n",
    "#         percentage_zeros = return_per_zeros(n_reads_per_gene/n_cells, phi)\n",
    "#         n_zeros = (percentage_zeros * n_cells).astype(int)\n",
    "\n",
    "    matrix_random = np.zeros((n_cells, n_genes))\n",
    "\n",
    "    for gene in tqdm(range(n_genes)):\n",
    "        if method == 'binomial':\n",
    "            rnd_idx = np.random.choice(np.arange(n_cells), n_reads_per_gene[gene])\n",
    "            bincount = np.bincount(rnd_idx)\n",
    "            matrix_random[:len(bincount), gene] = bincount\n",
    "\n",
    "        else:\n",
    "            raise TypeError('No method in list.')\n",
    "\n",
    "        # elif method in [\"negative binomial\", 'nb']:\n",
    "        #     if n_reads_per_gene[gene] + n_zeros > n_cells:\n",
    "        #         idx_nonzero = np.random.choice(np.arange(n_cells), n_cells - n_zeros, replace=False)\n",
    "        #         matrix_random[idx_nonzero, gene] += 1\n",
    "\n",
    "    return matrix_random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General matrix operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T12:01:18.593139Z",
     "start_time": "2020-02-08T12:01:18.585876Z"
    }
   },
   "outputs": [],
   "source": [
    "def return_mean_per(matrix):\n",
    "    # Returns the mean counts per gene, and the proportion of zeros\n",
    "    n_reads_per_gene = matrix.sum(0).astype(int)\n",
    "    n_zeros = (matrix == 0).sum(0)\n",
    "\n",
    "    return n_reads_per_gene/matrix.shape[0], n_zeros/matrix.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution functions\n",
    "There should be, convolution of binomial (corrected only, uncorrected should be appearing on the notebook), johnsonsu, ..., and convolution from initial read distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T12:01:19.796212Z",
     "start_time": "2020-02-08T12:01:19.784302Z"
    }
   },
   "outputs": [],
   "source": [
    "def apply_convolution_read_counts(d, knn = 5, threshold = 1, correct=True):\n",
    "    arr_0 = d.pmf(np.arange(int(d.ppf(threshold)) + 5))\n",
    "    if correct:\n",
    "        arr_0[0] = 0\n",
    "        arr_0 /= arr_0.sum()\n",
    "        \n",
    "    arr_i = d.pmf(np.arange(int(d.ppf(threshold)) + 5))\n",
    "    \n",
    "\n",
    "    arr_con = np.convolve(arr_0, arr_i,)\n",
    "    \n",
    "    arr_con  = arr_con[np.cumsum(arr_con) < threshold]\n",
    "    arr_con[arr_con < 0] = 0\n",
    "    \n",
    "    # Theoretically we should do that, but the effects are really small because the number of cells are high\n",
    "    for knni in range(2, knn):         \n",
    "        arr_con = np.convolve(arr_con, arr_i,)\n",
    "        \n",
    "        arr_con  = arr_con[np.cumsum(arr_con) < threshold]\n",
    "        arr_con[arr_con < 0] = 0\n",
    "        \n",
    "    return sts.rv_discrete(a=0, b=len(arr_con), values=(range(len(arr_con)), arr_con/sum(arr_con))), arr_con"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EMD(knn_counts, convolution, correct_std = True):\n",
    "    dist_range = np.arange(max(knn_counts)+1)\n",
    "    real_vals = np.bincount(knn_counts.astype(int))/len(knn_counts)\n",
    "    conv_vals = convolution.pmf(np.arange(max(knn_counts)+1))\n",
    "    \n",
    "    conv_vals[conv_vals < 0] = 0\n",
    "    \n",
    "    d = sts.wasserstein_distance(dist_range, dist_range, real_vals, conv_vals)\n",
    "    if correct_std: d /= convolution.std()\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_convolution(gene, adata, expression_counts_adata_norm_knn_norm, \n",
    "                     expression_counts_adata_norm_knn_random,\n",
    "                     adata_random, expression_counts_adata_random_knn_norm, \n",
    "                     expression_counts_adata_random_knn_random):\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 3, figsize=(12, 6))\n",
    "    \n",
    "    axs[0][0].set_title('Read counts, \\n%s, adata'%gene)\n",
    "    axs[0][1].set_title('Read random KNN counts, \\n%s, knn = %s, adata'%(gene, knn))\n",
    "    axs[0][2].set_title('Read KNN counts, \\n%s, knn = %s, adata'%(gene, knn))\n",
    "\n",
    "    counts_gene = adata[:, gene].X.ravel()\n",
    "    knn_random_counts = expression_counts_adata_norm_knn_random[gene]\n",
    "    knn_counts = expression_counts_adata_norm_knn_norm[gene]\n",
    "    \n",
    "    _ = axs[0][0].hist(counts_gene.tolist(), density=True, bins=int(max(counts_gene) - min(counts_gene)))\n",
    "    _ = axs[0][1].hist(knn_random_counts, density=True, bins=int(max(knn_random_counts) - min(knn_random_counts)))\n",
    "    _ = axs[0][2].hist(knn_counts, density=True, bins=int(max(knn_counts) - min(knn_counts)))\n",
    "\n",
    "    x_counts, y_counts = np.unique(counts_gene, return_counts=True)\n",
    "    d_c = sts.rv_discrete(a=0, b=len(counts_gene), values=(x_counts, y_counts/sum(y_counts)))\n",
    "\n",
    "    convolution, _ = apply_convolution_read_counts(d_c, knn = knn, threshold = 1)\n",
    "\n",
    "    range_ax = np.arange(int(1.2 * max(knn_counts)))\n",
    "\n",
    "    axs[0][1].plot(range_ax + 0.5, convolution.pmf(range_ax))\n",
    "    axs[0][2].plot(range_ax + 0.5, convolution.pmf(range_ax))\n",
    "    \n",
    "    d1 = EMD(knn_random_counts, convolution) \n",
    "    d2 = EMD(knn_counts, convolution) \n",
    "\n",
    "    axs[0][1].text(0.7 * axs[0][1].get_xlim()[1], 0.8 * axs[0][1].get_ylim()[1], '%.2f'%d1)\n",
    "    axs[0][2].text(0.7 * axs[0][2].get_xlim()[1], 0.8 * axs[0][2].get_ylim()[1], '%.2f'%d2)\n",
    "\n",
    "    \n",
    "    \n",
    "    axs[1][0].set_title('Read counts, \\n%s, adata_random'%gene)\n",
    "    axs[1][1].set_title('Read random KNN counts, \\n%s, knn = %s, adata_random'%(gene, knn))\n",
    "    axs[1][2].set_title('Read KNN counts, \\n%s, knn = %s, adata_random'%(gene, knn))\n",
    "\n",
    "    counts_gene = adata_random[:, gene].X.ravel()\n",
    "    knn_random_counts = expression_counts_adata_random_knn_random[gene]\n",
    "    knn_counts = expression_counts_adata_random_knn_norm[gene]\n",
    "    \n",
    "    _ = axs[1][0].hist(counts_gene.tolist(), density=True, bins=int(max(counts_gene) - min(counts_gene)))\n",
    "    _ = axs[1][1].hist(knn_random_counts, density=True, bins=int(max(knn_random_counts) - min(knn_random_counts)))\n",
    "    _ = axs[1][2].hist(knn_counts, density=True, bins=int(max(knn_counts) - min(knn_counts)))\n",
    "\n",
    "    \n",
    "    x_counts, y_counts = np.unique(counts_gene, return_counts=True)\n",
    "    d_c = sts.rv_discrete(a=0, b=len(counts_gene), values=(x_counts, y_counts/sum(y_counts)))\n",
    "\n",
    "    convolution, _ = apply_convolution_read_counts(d_c, knn = knn, threshold = 1)\n",
    "\n",
    "    range_ax = np.arange(int(1.2 * max(knn_counts)))\n",
    "\n",
    "    axs[1][1].plot(range_ax + 0.5, convolution.pmf(range_ax))\n",
    "    axs[1][2].plot(range_ax + 0.5, convolution.pmf(range_ax))\n",
    "\n",
    "    d1 = EMD(knn_random_counts, convolution) \n",
    "    d2 = EMD(knn_counts, convolution) \n",
    "\n",
    "    axs[1][1].text(0.7 * axs[1][1].get_xlim()[1], 0.8 * axs[1][1].get_ylim()[1], '%.2f'%d1)\n",
    "    axs[1][2].text(0.7 * axs[1][2].get_xlim()[1], 0.8 * axs[1][2].get_ylim()[1], '%.2f'%d2)\n",
    "    \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_zeros_non_zeros(gene, adata, expression_counts_knn_norm, expression_counts_knn_norm_with_zeros):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "    \n",
    "    axs[0].set_title('Read kNN counts, \\n%s, adata'%gene)\n",
    "    axs[1].set_title('Read kNN counts, with zeros, \\n%s, knn = %s, adata'%(gene, knn))\n",
    "\n",
    "    counts_gene = adata[:, gene].X.ravel()\n",
    "    knn_counts = expression_counts_knn_norm[gene]\n",
    "    knn_counts_with_zeros = expression_counts_knn_norm_with_zeros[gene]\n",
    "    \n",
    "    _ = axs[0].hist(knn_counts, density=True, bins=int(max(knn_counts) - min(knn_counts)))\n",
    "    _ = axs[1].hist(knn_counts_with_zeros, density=True, \n",
    "                       bins=int(max(knn_counts_with_zeros) - min(knn_counts_with_zeros)))\n",
    "\n",
    "    x_counts, y_counts = np.unique(counts_gene, return_counts=True)\n",
    "    d_c = sts.rv_discrete(a=0, b=len(counts_gene), values=(x_counts, y_counts/sum(y_counts)))\n",
    "\n",
    "    convolution, _ = apply_convolution_read_counts(d_c, knn = knn, threshold = 1, correct=True)\n",
    "    convolution_with_zeros, _ = apply_convolution_read_counts(d_c, knn = knn, threshold = 1, correct=False)\n",
    "\n",
    "    range_ax = np.arange(int(0.95 * min(knn_counts)), int(1.05 * max(knn_counts)))\n",
    "    range_ax_with_zeros = np.arange(int(0.95 * min(knn_counts_with_zeros)), \n",
    "                                    int(1.05 * max(knn_counts_with_zeros)))\n",
    "\n",
    "    axs[0].plot(range_ax + 0.5, convolution.pmf(range_ax))\n",
    "    axs[1].plot(range_ax_with_zeros + 0.5, convolution_with_zeros.pmf(range_ax_with_zeros))  \n",
    "    \n",
    "    d1 = EMD(knn_counts, convolution) \n",
    "    d0 = EMD(knn_counts_with_zeros, convolution_with_zeros) \n",
    "    \n",
    "    axs[0].text(0.7 * axs[0].get_xlim()[1], 0.8 * axs[0].get_ylim()[1], '%.2f'%d1)\n",
    "    axs[1].text(0.7 * axs[1].get_xlim()[1], 0.8 * axs[1].get_ylim()[1], '%.2f'%d0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset manipulation\n",
    "## Dataset download\n",
    "\n",
    "In this section we will include the download and basic preprocessing of the datasets. In the first subsection we will download the datasets (already preprocessed, or to be preprocessed), and in the second section we will process them. The processing will consist will be the basic one from scanpy.\n",
    "\n",
    "#### Svensson et al. (read solution - without cells)\n",
    "\n",
    "* Human ERCC + brain on Chromium: https://www.ebi.ac.uk/arrayexpress/experiments/E-MTAB-5480/\n",
    "\n",
    "* Mouse ERCC + mESC on Smartseq2: https://www.ebi.ac.uk/arrayexpress/experiments/E-MTAB-5481/\n",
    "\n",
    "* Mouse ERCC + mESC on Smarter C1: https://www.ebi.ac.uk/arrayexpress/experiments/E-MTAB-5483/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T11:39:06.402752Z",
     "start_time": "2020-02-08T11:39:06.398409Z"
    }
   },
   "outputs": [],
   "source": [
    "fastq_dir = \"/media/seth/SETH_DATA/SETH_Alex/triku/data/svensson/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cd $fastq_dir && aria2c -x 16 ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR187/006/ERR1876146/ERR1876146.fastq.gz --max-file-not-found 10 -c --file-allocation=none"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10x datasets\n",
    "* neuron 10k: http://cf.10xgenomics.com/samples/cell-exp/3.0.0/neuron_10k_v3/neuron_10k_v3_filtered_feature_bc_matrix.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T12:01:25.570191Z",
     "start_time": "2020-02-08T12:01:25.566574Z"
    }
   },
   "outputs": [],
   "source": [
    "fastq_dir = \"/media/seth/SETH_DATA/SETH_Alex/triku/data/10x/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cd $fastq_dir && wget http://cf.10xgenomics.com/samples/cell-exp/3.0.0/neuron_10k_v3/neuron_10k_v3_filtered_feature_bc_matrix.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Svensson et al. (read solution, without cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "# For E-MTAB-5480\n",
    "index_dir = \"/media/seth/SETH_DATA/SETH_Alex/ARAUZO_02/seq_indexes/kallisto\"\n",
    "umis_dir = \"/media/seth/SETH_DATA/SETH_Alex/Programs/\"\n",
    "fastq_dir = \"/media/seth/SETH_DATA/SETH_Alex/triku/data/svensson/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "# you need to install umis from here\n",
    "# !cd $umis_dir && git clone https://github.com/vals/umis && cd umis && pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform fastq file to kallisto-readdable format\n",
    "# THE FASTQ MUST BE UNZIPPED\n",
    "# !cd $fastq_dir && python $fastq_dir/process_umi.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !loompy fromfq $fastq_dir/svensson10x.loom svensson10x $index_dir $fastq_dir/metadata.tab $fastq_dir/ERR1876146.fastq.gz $fastq_dir/ERR1876146_UMI.fastq.gz $fastq_dir/ERR1876146_CB.fastq.gz "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preprocessing\n",
    "The preprocessing of the datasets consists of two parts:\n",
    "- First, we will apply a basic processing (filter genes + PCA + neighbors + umap). We exclude HVGs and log / norm because log alters the structure of the dataset, and the structure of the % zeros VS mean graph.\n",
    "- Second, we will apply a randomization of the matrix, i.e. for each gene, we will distribute its reads within the cells.  The distribution of those reads follows a binomial distribution, which we will see id the expected output. This random matrix will then be processed as the previous one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Svensson et al. (read solution, without cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T11:39:06.402752Z",
     "start_time": "2020-02-08T11:39:06.398409Z"
    }
   },
   "outputs": [],
   "source": [
    "fastq_dir = \"/media/seth/SETH_DATA/SETH_Alex/triku/data/svensson/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T11:39:16.498315Z",
     "start_time": "2020-02-08T11:39:11.272532Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svensson_10x_adata = sc.read_loom(fastq_dir + '/svensson10x.loom')\n",
    "svensson_10x_adata.X = np.asarray(svensson_10x_adata.X.todense())\n",
    "svensson_10x_adata.var_names_make_unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T11:39:16.502163Z",
     "start_time": "2020-02-08T11:39:12.193Z"
    }
   },
   "outputs": [],
   "source": [
    "sc.pp.filter_genes(svensson_10x_adata, min_cells=20)\n",
    "sc.pp.calculate_qc_metrics(svensson_10x_adata, inplace=True)\n",
    "sc.pp.pca(svensson_10x_adata)\n",
    "sc.pp.neighbors(svensson_10x_adata, metric='cosine')\n",
    "sc.tl.umap(svensson_10x_adata)\n",
    "sc.tl.leiden(svensson_10x_adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T11:19:57.313734Z",
     "start_time": "2020-02-08T11:19:53.189847Z"
    }
   },
   "outputs": [],
   "source": [
    "sc.pl.umap(svensson_10x_adata, color='leiden')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is indeed some heterogeneity in clusters, so they are not completely random, and we will see it indeed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T11:19:59.659751Z",
     "start_time": "2020-02-08T11:19:57.582485Z"
    }
   },
   "outputs": [],
   "source": [
    "mean, zeros = return_mean_per(svensson_10x_adata.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T11:52:57.394882Z",
     "start_time": "2020-02-08T11:52:57.378717Z"
    }
   },
   "outputs": [],
   "source": [
    "random_svensson10x = create_random_count_matrix(svensson_10x_adata.X)\n",
    "random_svensson10x_adata = sc.AnnData(X = random_svensson10x)\n",
    "random_svensson10x_adata.var_names, random_svensson10x_adata.obs_names = svensson_10x_adata.var_names, svensson_10x_adata.obs_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_random, zeros_random = return_mean_per(random_svensson10x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.pca(random_svensson10x_adata)\n",
    "sc.pp.neighbors(random_svensson10x_adata, metric='cosine')\n",
    "sc.tl.umap(random_svensson10x_adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T11:20:02.029295Z",
     "start_time": "2020-02-08T11:15:42.987Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'m': np.log10(mean), 'z': zeros, 'n': svensson_10x_adata.var_names.values})\n",
    "df_random = pd.DataFrame({'m': np.log10(mean_random), 'z': zeros_random, 'n': svensson_10x_adata.var_names.values})\n",
    "\n",
    "p = figure(tools=\"box_zoom,hover,reset\", plot_height=400, plot_width=400, tooltips=[(\"Gene\",\"@n\")])\n",
    "p.scatter('m', 'z', source=df_random, color='#ababab', alpha=0.9)\n",
    "p.scatter('m', 'z', source=df, color='firebrick', alpha=0.9)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that even despite being *random*, the real distribution is not as the theoretical random distribution. We will later see those biases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10x neurons 10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T12:01:25.570191Z",
     "start_time": "2020-02-08T12:01:25.566574Z"
    }
   },
   "outputs": [],
   "source": [
    "fastq_dir = \"/media/seth/SETH_DATA/SETH_Alex/triku/data/10x/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T12:01:30.129349Z",
     "start_time": "2020-02-08T12:01:28.428216Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "neurons_10k_adata = sc.read_10x_h5(fastq_dir + '/neuron_10k_v3_filtered_feature_bc_matrix.h5')\n",
    "neurons_10k_adata.var_names_make_unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T12:01:42.410339Z",
     "start_time": "2020-02-08T12:01:40.988089Z"
    }
   },
   "outputs": [],
   "source": [
    "todense_arr = np.asarray(neurons_10k_adata.X.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons_10k_adata = sc.AnnData(X = todense_arr, obs=pd.DataFrame(index=neurons_10k_adata.obs.index),\n",
    "                   var=pd.DataFrame(index=neurons_10k_adata.var.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T11:53:47.087982Z",
     "start_time": "2020-02-08T11:53:13.020714Z"
    }
   },
   "outputs": [],
   "source": [
    "sc.pp.filter_genes(neurons_10k_adata, min_cells=20)\n",
    "sc.pp.calculate_qc_metrics(neurons_10k_adata, inplace=True)\n",
    "sc.pp.pca(neurons_10k_adata)\n",
    "sc.pp.neighbors(neurons_10k_adata)\n",
    "sc.tl.umap(neurons_10k_adata)\n",
    "sc.tl.leiden(neurons_10k_adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T11:54:05.625305Z",
     "start_time": "2020-02-08T11:53:55.324775Z"
    }
   },
   "outputs": [],
   "source": [
    "mean, zeros = return_mean_per(neurons_10k_adata.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T11:53:47.838310Z",
     "start_time": "2020-02-08T11:53:47.156530Z"
    }
   },
   "outputs": [],
   "source": [
    "sc.pl.umap(neurons_10k_adata, color='leiden')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is indeed some heterogeneity in clusters, se they are not completely random, and we will see it indeed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T11:54:34.771498Z",
     "start_time": "2020-02-08T11:54:25.580916Z"
    }
   },
   "outputs": [],
   "source": [
    "random_neurons10k = create_random_count_matrix(neurons_10k_adata.X)\n",
    "random_neurons10k_adata = sc.AnnData(X = random_neurons10k)\n",
    "random_neurons10k_adata.var_names, random_neurons10k_adata.obs_names = neurons_10k_adata.var_names, neurons_10k_adata.obs_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T11:54:34.777631Z",
     "start_time": "2020-02-08T11:54:33.770Z"
    }
   },
   "outputs": [],
   "source": [
    "mean_random, zeros_random = return_mean_per(random_neurons10k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T11:54:34.775221Z",
     "start_time": "2020-02-08T11:54:31.905Z"
    }
   },
   "outputs": [],
   "source": [
    "sc.pp.pca(random_neurons10k_adata)\n",
    "sc.pp.neighbors(random_neurons10k_adata, metric='cosine')\n",
    "sc.tl.umap(random_neurons10k_adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NB_prop(mu, phi):\n",
    "    return ((phi**(-1))/((phi**(-1))+mu))**(phi**(-1))\n",
    "\n",
    "phi_exp_random, pcov = opt.curve_fit(NB_prop, mean_random, zeros_random)\n",
    "phi_exp, pcov = opt.curve_fit(NB_prop, mean, zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T11:20:02.056300Z",
     "start_time": "2020-02-08T11:15:58.513Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'m': np.log10(mean), 'z': zeros, 'n': neurons_10k_adata.var_names.values})\n",
    "df_random = pd.DataFrame({'m': np.log10(mean_random), 'z': zeros_random, 'n': neurons_10k_adata.var_names.values})\n",
    "\n",
    "p = figure(tools=\"box_zoom,hover,reset\", plot_height=400, plot_width=400, tooltips=[(\"Gene\",\"@n\")])\n",
    "p.scatter('m', 'z', source=df_random, color='#ababab', alpha=0.7)\n",
    "p.scatter('m', 'z', source=df, color='firebrick', alpha=0.7)\n",
    "\n",
    "x_dots = np.linspace(np.log10(min(mean)), np.log10(max(mean)), 150)\n",
    "p.line(x_dots, NB_prop(10**x_dots, phi_exp[0]), color='white')\n",
    "\n",
    "x_dots = np.linspace(np.log10(min(mean_random)), np.log10(max(mean_random)), 150)\n",
    "p.line(x_dots, NB_prop(10**x_dots, phi_exp_random[0]), color='black')\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons_10k_adata.uns['neighbors']['params']['n_neighbors']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The rationale behind using kNN read counts\n",
    "Highly variable genes are defined as genes with high variability of counts within a specific mean range. Those genes are used when doing downstream to reduce the dimensionality of the dataset, and select the most \"informative\" genes from the dataset. \n",
    "\n",
    "In the M3Drop pipeline, HVG selection is done considering the mean expression, and percentage of zeros. Theoretically, given a set of genes with similar genes, genes with a higher percentage of zeros concentrate their reads in a subset of cells, that is, there are more cells with fewer counts, whereas some cells have a higher read count. Generally, genes with higher percentage of zeros tend to have more expression in localized sets of cells, which results in a specific expression of the gene, and thus a biological function can be assumed to it. \n",
    "\n",
    "In this section we will study which distributions arise using the following method: for a selected mean gene count $\\mu$, and a threshold $\\epsilon$, we will consider the genes with mean expression in the range $(\\mu - \\epsilon, \\mu + \\epsilon)$. From those genes, we will consider the ones with the highest percentage of zeros, and the lowest percentage of zeros. We will see how the distribution of reads, and reads in the kNN follow (more or less closely) a binomial distribution, whereas for genes with higher percentage of zeros this does not follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T11:20:02.058676Z",
     "start_time": "2020-02-08T11:16:01.355Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_distributions(adata, adata_random, mu, eps):\n",
    "    mean_adata, per_adata = return_mean_per(adata.X)\n",
    "\n",
    "    idx = (np.log10(mean_adata) > mu - eps)& (np.log10(mean_adata) < mu + eps)\n",
    "    selected_genes = adata.var_names[idx]\n",
    "    pers = per_adata[idx]\n",
    "    min_gene, max_gene = selected_genes[np.argmin(pers)], selected_genes[np.argmax(pers)]\n",
    "    \n",
    "    knn_indices = return_knn_indices(adata.X)\n",
    "    knn_counts, cat = return_expression_info([min_gene, max_gene], adata, knn_indices, category_name = 0)\n",
    "    knn_indices_random = return_knn_indices(adata_random.X)\n",
    "    knn_counts_random, cat = return_expression_info([min_gene, max_gene], adata_random, knn_indices, category_name = 0)\n",
    "    \n",
    "    fig = plt.figure(figsize=(14,8))\n",
    "    ax1, ax2, ax3, ax4 = fig.add_subplot(241), fig.add_subplot(242), fig.add_subplot(243), fig.add_subplot(244)\n",
    "    ax5, ax6, ax7, ax8 = fig.add_subplot(245), fig.add_subplot(246), fig.add_subplot(247), fig.add_subplot(248)\n",
    "    \n",
    "    for ax in [ax1, ax2, ax3, ax4]:\n",
    "        ax.set_yscale('log')\n",
    "    nbins = 45\n",
    "    \n",
    "    # Plot with counts of gene near bottom\n",
    "    ax1.set_title(min_gene + ' (~ random)  \\ncount distribution')\n",
    "    counts_gene_min = adata[:, min_gene].X.flatten()\n",
    "    sns.distplot(counts_gene_min, kde=False, ax=ax1, bins=nbins)\n",
    "\n",
    "        \n",
    "    # Plot with counts of gene near bottom, but randomized\n",
    "    ax2.set_title(min_gene + ' random \\ncount distribution')\n",
    "    counts_gene_min_random = adata_random[:, min_gene].X.flatten()\n",
    "    sns.distplot(counts_gene_min_random, kde=False, ax=ax2, bins=nbins, color='red')\n",
    "\n",
    "        \n",
    "    # Plot with counts of gene at top\n",
    "    ax3.set_title(max_gene + ' (not random) \\ncount distribution')\n",
    "    counts_gene_max = adata[:, max_gene].X.flatten()\n",
    "    sns.distplot(counts_gene_max, kde=False, ax=ax3, bins=nbins)\n",
    "\n",
    "    \n",
    "    # Plot with counts of gene at top, but randomized\n",
    "    ax4.set_title(max_gene + ' random \\ncount distribution')\n",
    "    counts_gene_max_random = adata_random[:, max_gene].X.flatten()\n",
    "    sns.distplot(counts_gene_max_random, kde=False, ax=ax4, bins=nbins, color='red')\n",
    "    \n",
    "    \n",
    "   \n",
    "    # Plot with KNN counts of gene near bottom\n",
    "    ax5.set_title(min_gene + ' (~ random) \\nknn distribution')\n",
    "    sns.distplot(knn_counts[min_gene], kde=False, ax=ax5, bins=nbins)  \n",
    "    \n",
    "    # Plot with KNN counts of gene near bottom, but randomized\n",
    "    ax6.set_title(min_gene + ' random \\nknn distribution')\n",
    "    sns.distplot(knn_counts_random[min_gene], kde=False, ax=ax6, bins=nbins, color='red')\n",
    "        \n",
    "    # Plot with KNN counts of gene at top\n",
    "    ax7.set_title(max_gene + ' (not random) \\nknn distribution')\n",
    "    counts_gene_max = adata[:, max_gene].X\n",
    "    sns.distplot(knn_counts[max_gene], kde=False, ax=ax7, bins=nbins)\n",
    "\n",
    "    \n",
    "    # Plot with KNN counts of gene at top, but randomized\n",
    "    ax8.set_title(max_gene + ' random \\nknn distribution')\n",
    "    sns.distplot(knn_counts_random[max_gene], kde=False, ax=ax8, bins=nbins, color='red')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    sc.pl.umap(adata, color=[min_gene, max_gene], cmap=magma)\n",
    "    sc.pl.umap(adata_random, color=[min_gene, max_gene], cmap=magma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How do we interpret the plot?**\n",
    "\n",
    "On the first row we will calculate the **distribution of reads** in the dataset for the gene with smallest and biggest percentage of zeros. In blue appear the distributions of reads from the *biological* dataset, and in red for the random dataset. The pair of blue / red plots on the left represent the gene with smallest percentage of zeros, and the plots on the right represent the gene with highest percentage of zeros.\n",
    "We generally see that for the *biological* dataset, the distributions of reads are more skewed.\n",
    "\n",
    "The second row shows the distribution of reads for the kNN. To calculate the distribution of kNN, for each **cell with positive expression**, we consider their neighbors. The selection of cells with positive expression is arbritary, but for genes with low expression the resulting distributions are much more \"real like\", sice there is not an spike in zeros.\n",
    "\n",
    "The third and fourth rows correspond to the UMAP representations of the *biological* and randomized adatas. We observe that, as usual, the randomized UMAP shows a random distribution of points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution plotting on Svensson control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T11:20:02.060898Z",
     "start_time": "2020-02-08T11:16:02.796Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_distributions(svensson_10x_adata, random_svensson10x_adata, -1.6, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T11:20:02.063221Z",
     "start_time": "2020-02-08T11:16:03.800Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_distributions(svensson_10x_adata, random_svensson10x_adata, -1.1, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T11:20:02.065672Z",
     "start_time": "2020-02-08T11:16:04.090Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_distributions(svensson_10x_adata, random_svensson10x_adata, -0.85, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T11:20:02.068313Z",
     "start_time": "2020-02-08T11:16:04.312Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_distributions(svensson_10x_adata, random_svensson10x_adata, -0.6, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T11:20:02.070473Z",
     "start_time": "2020-02-08T11:16:04.571Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_distributions(svensson_10x_adata, random_svensson10x_adata, 0, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distributions(svensson_10x_adata, random_svensson10x_adata, 0.3, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T11:20:02.072894Z",
     "start_time": "2020-02-08T11:16:05.098Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_distributions(svensson_10x_adata, random_svensson10x_adata, 0.6, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T11:20:02.075144Z",
     "start_time": "2020-02-08T11:16:05.643Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_distributions(svensson_10x_adata, random_svensson10x_adata, 1, 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this dataset is composed of reads, and not of cells, we should expect a random *behaviour* of the genes. We see it is indeed the case: for all ranges the distributions of counts and kNN counts are similar, with the exception of some minor differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution plotting on Neurons 10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T11:20:02.060898Z",
     "start_time": "2020-02-08T11:16:02.796Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_distributions(neurons_10k_adata, random_neurons10k_adata, -1.6, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T11:20:02.063221Z",
     "start_time": "2020-02-08T11:16:03.800Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_distributions(neurons_10k_adata, random_neurons10k_adata, -1.1, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T11:20:02.065672Z",
     "start_time": "2020-02-08T11:16:04.090Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_distributions(neurons_10k_adata, random_neurons10k_adata, -0.85, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T11:20:02.068313Z",
     "start_time": "2020-02-08T11:16:04.312Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_distributions(neurons_10k_adata, random_neurons10k_adata, -0.6, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T11:20:02.070473Z",
     "start_time": "2020-02-08T11:16:04.571Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_distributions(neurons_10k_adata, random_neurons10k_adata, 0, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distributions(neurons_10k_adata, random_neurons10k_adata, 0.3, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T11:20:02.072894Z",
     "start_time": "2020-02-08T11:16:05.098Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_distributions(neurons_10k_adata, random_neurons10k_adata, 0.6, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T11:20:02.075144Z",
     "start_time": "2020-02-08T11:16:05.643Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_distributions(neurons_10k_adata, random_neurons10k_adata, 1.6, 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do see that the distribution of reads in the kNN of the gene with fewest percentage of zeros has, indeed, a similar distribution to the random dataset. This number is even more similar to the distribution in the random dataset when we evaluate genes with smaller mean expression. \n",
    "\n",
    "However, the distribution of reads in the kNN obtained from the random dataset is not really the same distribution as the one obtained from randomly sampling N cells and finding their distribution. In the next section we will reveal an approximation to that distribution, which is fair enough for the number of neighbors we are considering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wasserstein distance for comparison of distributions\n",
    "\n",
    "Wasserstein distance is also known as Earth Mover Distance, due to the intuitive interpretation of the distance: given two distributions (or piles of earth) with the same area, the Wasserstein distance represents the minimum amount of mass that has to be moved to transform one distribution into the other. Wasserstein distance has been shown to outperform other distribution comparison metrics, such as KL or JS distances.\n",
    "\n",
    "In this section we will apply some examples of the Wasserstein distance to get an intuition of its values, and then we will explain how it can be modified to account for distributions at different orders of magnitude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wasserstein distance on toy examples\n",
    "\n",
    "For this section we will in include examples of simple distributions, and see which are the distances.\n",
    "\n",
    "The nomenclature of the function is \n",
    "`sts.wasserstein_distance(dist_range_1, dist_range_2, dist_height_1, dist_height_2)`\n",
    "where `dist_range_1` and `dist_range_2` are the positions of the x axis of the distribution, and `dist_height_1` and `dist_height_2` are the heights (or frequencies) of the distributions at the x values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 0: two equal distributions\n",
    "d_0 = sts.wasserstein_distance([0, 1], [0, 1], [1, 1], [1, 1])\n",
    "\n",
    "print('Wasserstein distance for equal distributions: {}'.format(d_0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, if the distributions are equal, the distance is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1 and 2: move a whole distribution 1 and 2 places\n",
    "d_1 = sts.wasserstein_distance([0, 1], [1, 2], [1, 1], [1, 1])\n",
    "print('Wasserstein distance for D1: {}'.format(d_1))\n",
    "\n",
    "d_2 = sts.wasserstein_distance([0, 1], [2, 3], [1, 1], [1, 1])\n",
    "print('Wasserstein distance for D1: {}'.format(d_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `d_1` we have to move the pile at [1, 2] to [0, 1]. For that, the least expensive option is to move the block at 1 to 0, and the one at 2 to 1; or keep the block at 1 static and move the one at 2 to 0. In the first option we are moving $0.5\\cdot 1 + 0.5\\cdot 1 = 1$, and in the second we are moving $0.5 \\cdot 0 + 0.5 \\cdot 2 = 1$.\n",
    "\n",
    "For `d_2` we are moving the whole distribution two positions, which is equivalent to moving it two times  ($0.5\\cdot 2 + 0.5 \\cdot 2 = 2$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the last part we are going to analyze the examples at scipy's documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_3 = sts.wasserstein_distance([0, 1, 3], [5, 6, 8]) # We omit the heights of one\n",
    "print('Wasserstein distance for D3: {}'.format(d_3))\n",
    "\n",
    "d_4 = sts.wasserstein_distance([0, 1], [0, 1], [3, 1], [2, 2])\n",
    "print('Wasserstein distance for D4: {}'.format(d_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the third example we are moving a distribution with three blocks from one position to another. We see that both distributions are the same, but shifted 5 positions. Therefore, we have moved the distribution 5 times.\n",
    "\n",
    "In the fourth example we have two distributions of four blocks, and to move the first one into the second one, we have to move one block from 0 to 1. Since we have moved 1 block out of 4, the total weight moved is a 25% of the distribution and, thus, `d_4 = 0.25`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we do see that the intuition of the Wasserstein distance is how many times the distribution has to be moved to convert into the second one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wasserstein on different scales\n",
    "\n",
    "Distribution of read counts or kNN counts on single cell vary in a wide scale, ranging from units to thousands of units of difference. This is a problem, because distributions at higher orders of magnitude have higher distances, and thus Wasserstein distance will scale linearly with the scale of the distribution.\n",
    "\n",
    "To see that, we will calculate the Wasserstein distance for two cases of normal distributions:\n",
    "* $N(0,1)$ VS $N(5,1)$\n",
    "* $N(0, 100)$ VS $(500, 100)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts.wasserstein_distance(sts.norm.rvs(0, 1, 100000), sts.norm.rvs(5, 1, 100000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts.wasserstein_distance(sts.norm.rvs(0, 100, 100000), sts.norm.rvs(500, 100, 100000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We clearly see that the distribution increases linearly with the scale, and also, with the standard deviation.\n",
    "Therefore, we can *scale* down the distribution if we divide it by the standard distribution of one of the two functions. This way, we still have the sense of how many times the distribution has to be moved, without considering the scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts.wasserstein_distance(sts.norm.rvs(0, 1, 100000), sts.norm.rvs(5, 1, 100000)) / np.std(sts.norm.rvs(0, 1, 100000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts.wasserstein_distance(sts.norm.rvs(0, 100, 100000), sts.norm.rvs(500, 100, 100000)) / np.std(sts.norm.rvs(0, 100, 100000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since, for our case, we have to compare the distribution obtained by convoluting the reads from a gene kNN times, which is the *theoretical distribution* to the distribution of kNN reads, we will choose the standard distribution of the theoretical distribution to calculate the distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximating the distribution of reads in N random cells\n",
    "\n",
    "In the following sections we will analyze how can we model the distribution of kNN reads given a prior distribution. This will be interesting, because we can later analyze the difference between the theoretical distribution and the *real* one.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's imagine a dataset with $C$ cells, $N$ of which are selected, and their number of reads are counted. Let's suppose that the number of counts follows a distribution $X$. \n",
    "\n",
    "The distribution of reads in 1 cell is, simply, the distribution $X$, which we will also call $X_1$. The distribution of reads given 2 cells, or $X_2$ is the *sum* of the two distributions. \n",
    "\n",
    "We will see an example of that sum. Let's suppose that $X_1$ is described as follows: (proportions are relative to 1 to make calculations easier).\n",
    "\n",
    "$P(X_1 = 1) = 1; P(X_1 = 2) = 3; P(X_1 = 3) = 7; P(X_1 = 4) = 5; P(X_1 = 5) = 2; P(X_1 = 6) = 1$\n",
    "\n",
    "In order to calculate the distribution of $X_2$, we will see an example of some values:\n",
    "\n",
    "* $P(X_2 = 2) = P(X_1 = 1) \\cdot P(X_1 = 1) = 1$\n",
    "* $P(X_2 = 4) = P(X_1 = 2) \\cdot P(X_1 = 2) + P(X_1 = 1) \\cdot P(X_1 = 3) +  P(X_1 = 3) \\cdot P(X_1 = 1) = 3\\cdot 3 + 2\\cdot(7\\cdot1) = 23$\n",
    "* $P(X_2 = 9) = P(X_1 = 6) \\cdot P(X_1 = 3) + P(X_1 = 3) \\cdot P(X_1 = 6) + P(X_1 = 5) \\cdot P(X_1 = 4) + P(X_1 = 4) \\cdot P(X_1 = 5) = 2\\cdot(1\\cdot 7 + 2\\cdot5) = 34$\n",
    "\n",
    "In the case of $P(X_1 = 2) \\cdot P(X_1 = 2)$ we should technically do $P(X_1 = 2) \\cdot (P(X_1 = 2) - 1)$, since one of the elements has already been chosen. However, we will ignore this fact to make the operations easier.\n",
    "\n",
    "So, if we want to generalize the sum to $P(X_2 = k)$, then, we have to find all pairs $(a,b)$ such that $a + b =k$, and compute the sum of events. This *sum* is called convolution, that is, the distribution arosen from all the combination of elements from the distribution $X$. Mathematically, given two probability distributions \n",
    "$f,g$, the convolution of $f$ in $g$ for a value $k$ is:\n",
    "\n",
    "$$ (f*g)[k] = \\sum_{m = -\\infty}^{\\infty} f[m]g[k-m] $$\n",
    "\n",
    "In this case $m$ will be bounded between 1 and 6. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why counting kNN reads from cells with positive expression is better\n",
    "When counting the reads from the kNN we can consider the reads in kNN from cells with zero counts, or exclude them. That is, if we have the distribution of counts:\n",
    "\n",
    "$P(X_1 = 0) = 0.9, P(X_1 = 1) = 0.05, P(X_1 = 2) = 0.03, P(X_1 = 3) = 0.015, P(X_1 = 4) = 0.005$\n",
    "\n",
    "We consider the distribution $\\hat{X}_1$:\n",
    "\n",
    "$P(X_1 = 1) = 0.5 , P(X_1 = 2) = 0.3, P(X_1 = 3) = 0.15, P(X_1 = 4) = 0.05$\n",
    "\n",
    "Which is the one obtained after removing $P(X_1 = 0) = 0.9$ and adjusting the proportions to sum to 1. \n",
    "\n",
    "The first iteration, that is, the distribution of reads, is $\\hat{X}_1$; then the distribution of reads for two cells is $\\hat{X}_1 = \\hat{X}_1*X_1$, and, for $N$ reads, the final distribution of reads is $\\hat{X}_N = \\hat{X}_1*X_1*\\cdots_{n-1}*X_1$. For genes with larger expression values the difference between $\\hat{X}_N$ and $X_N$ are not that relevant, but for genes with few counts, it becomes relevant. In the next cell we will calculate $\\hat{X}_N$ and $X_N$ for genes with low and high counts, and\n",
    "we will see that $\\hat{X}_N$ sometimes is the best fitting ditribution. \n",
    "\n",
    "The rationale behind considering reads with positive counts is that for genes with low expression, the differences become more apparent with high percentage of zeros, and remain similar with lower percentages of zeros. Also, genes with high expression will not be affected by this measure. This thus should favor the selection of genes with lower expression, which sometimes can be neglected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show that, we are going to use a distance (we will explain which one later on) and genes with low, low-mid, mid and high expression; based on having a low or high percentage of zeros.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_genes = ['Tpcn2', 'Pex11g', 'Rgs1', 'Rac2', 'Usp20',\n",
    "              'Cln8', 'Spp1', 'Vwa1', 'Rbm6', 'Ogt', \n",
    "             'Pcp4', 'Opcml', 'Rsrp1', 'mt-Nd4', 'Tubb2a', 'Tubb3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = neurons_10k_adata.copy()\n",
    "knn = int(0.5 * adata.X.shape[0] ** 0.5)\n",
    "knn_indices_knn_norm = return_knn_indices(adata.X, knn=knn, return_random=False) \n",
    "expression_counts_knn_norm, categories = return_expression_info(list_genes, adata, \n",
    "                                                                           knn_indices_knn_norm, \n",
    "                                                           category_name = 0, zero_counts=False)\n",
    "\n",
    "\n",
    "expression_counts_knn_norm_with_zeros, categories = return_expression_info(list_genes, adata, \n",
    "                                                                           knn_indices_knn_norm, \n",
    "                                                           category_name = 0, zero_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "knn_indices_knn_norm = return_knn_indices(adata.X, knn=knn, return_random=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "sc.pp.neighbors(adata, n_neighbors=knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "# Those are genes with high percentage of zeros\n",
    "# Rac2 - Low expression\n",
    "# Vwa1 - Low-mid expression\n",
    "# Opcml - Mid expression\n",
    "# Tubb2a - High expression\n",
    "\n",
    "for gene in ['Rac2', 'Vwa1', 'Opcml', 'Tubb2a', \n",
    "             ]:\n",
    "    compare_zeros_non_zeros(gene, adata, \n",
    "        expression_counts_knn_norm, \n",
    "        expression_counts_knn_norm_with_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "# Those are genes with low percentage of zeros\n",
    "# Tpcn2 - Low expression\n",
    "# Usp20 - Low-mid expression\n",
    "# Rbm6 - Mid expression\n",
    "# Rsrp1 - High expression\n",
    "\n",
    "for gene in ['Tpcn2',  'Usp20', 'Rbm6',  'Rsrp1',]:\n",
    "    compare_zeros_non_zeros(gene, adata, \n",
    "        expression_counts_knn_norm, \n",
    "        expression_counts_knn_norm_with_zeros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that using the kNN reads of positively-expressed cells, the distances and the plots at lower expressions become more clear, whereas for high expression genes the differences are not so apparent. We also see that for genes with lower percentage of zeros, that is, which are expected to behave like *random* expressing genes, do not show that much difference between including or not zero-expressing cells, which should be expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_genes = ['CCDC82', 'CAV1', 'PFDN1', 'ATP5MC2', 'RPL34', 'MT-ND2', 'MT-RNR2', 'MBP', 'UBB'] # Svensson\n",
    "list_genes = ['Ubiad1', 'Rspo1', 'Cog3', 'Lyz2', 'Zfp688', 'Ccl3', 'Gpr107', 'Vtn', 'Dhx30', 'Sparc', 'Rbm25',\n",
    "             'Opcml', 'Neurod2', 'Ptma', 'Eef1a1', \n",
    "             'Cbarp', 'Pdlim4', 'Vim', 'Hmgb2', 'Ccl2', 'Csf1', 'Mmab', 'Pecam1', 'Gja1', 'Rims4'] # Neuron 10x\n",
    "list_genes = ['Ccl12', 'Rac2', 'Tap1', 'Disp1', 'Zic1', 'Eva1b', 'Zfp3', 'Fbxl20', 'Clic1', 'Jun', \n",
    "              'Clk4', 'Tra2a', 'Meis2', 'Tubb3', 'Rsrp1', 'mt-Nd4', 'Malat1', 'Ppia', 'mt-Co1', 'mt-Co3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = neurons_10k_adata.copy()\n",
    "knn = int(0.5 * adata.X.shape[0] ** 0.5)\n",
    "knn_indices_adata_norm_knn_norm = return_knn_indices(adata.X, knn=knn, return_random=False) \n",
    "expression_counts_adata_norm_knn_norm, categories = return_expression_info(list_genes, adata, \n",
    "                                                                           knn_indices_adata_norm_knn_norm, \n",
    "                                                           category_name = 0)\n",
    "\n",
    "\n",
    "knn_indices_adata_norm_knn_random = return_knn_indices(adata.X, knn=knn, return_random=True) \n",
    "expression_counts_adata_norm_knn_random, categories = return_expression_info(list_genes, adata, \n",
    "                                                                           knn_indices_adata_norm_knn_random, \n",
    "                                                           category_name = 0)\n",
    "\n",
    "\n",
    "\n",
    "adata_random = random_neurons10k_adata.copy()\n",
    "knn = int(0.5 * adata.X.shape[0] ** 0.5)\n",
    "knn_indices_adata_random_knn_norm = return_knn_indices(adata_random.X, knn=knn, return_random=False) \n",
    "expression_counts_adata_random_knn_norm, categories = return_expression_info(list_genes, adata_random, \n",
    "                                                                           knn_indices_adata_random_knn_norm, \n",
    "                                                           category_name = 0)\n",
    "\n",
    "\n",
    "knn_indices_adata_random_knn_random = return_knn_indices(adata_random.X, knn=knn, return_random=True) \n",
    "expression_counts_adata_random_knn_random, categories = return_expression_info(list_genes, adata_random, \n",
    "                                                                           knn_indices_adata_random_knn_random, \n",
    "                                                           category_name = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how well does the convolution fit the real kNN distribution, we are going to plot the following plot for several genes. The plot consists of 3 columns and 2 rows.\n",
    "\n",
    "**Rows**: first row contains results using the original adata, and second row contains results using the randomised adata.\n",
    "\n",
    "**Columns**: \n",
    "* First column contains the read counts\n",
    "* Second column contains the counts of a random selection of NN per cell.\n",
    "* Third column contains the counts of the kNN based on cosine distance.\n",
    "\n",
    "To see the effect of the mean number of read counts and the percentage of zeros, we are going to do the plot for\n",
    "5 categories of means (low [-2.5, -1.5], low-mid [-1.5, -0.5], mid [-0.5, 0.5], mid-high [0.5, 1.5] and high [1.5, 2.5]), and 2 categories of percentage of zeros (high and low).\n",
    "\n",
    "Looking at the graph of percentage of zeros VS mean read count, at high and low means there should be not that much difference between high and low percentages of zeros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOW mean, HIGH percentage of zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_convolution('Rac2', adata, expression_counts_adata_norm_knn_norm, expression_counts_adata_norm_knn_random,\n",
    "                     adata_random, expression_counts_adata_random_knn_norm, expression_counts_adata_random_knn_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOW mean, LOW percentage of zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_convolution('Tap1', adata, expression_counts_adata_norm_knn_norm, expression_counts_adata_norm_knn_random,\n",
    "                     adata_random, expression_counts_adata_random_knn_norm, expression_counts_adata_random_knn_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOW-MID mean, HIGH percentage of zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_convolution('Zic1', adata, expression_counts_adata_norm_knn_norm, expression_counts_adata_norm_knn_random,\n",
    "                     adata_random, expression_counts_adata_random_knn_norm, expression_counts_adata_random_knn_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOW-MID mean, LOW percentage of zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_convolution('Fbxl20', adata, expression_counts_adata_norm_knn_norm, expression_counts_adata_norm_knn_random,\n",
    "                     adata_random, expression_counts_adata_random_knn_norm, expression_counts_adata_random_knn_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MID mean, HIGH percentage of zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_convolution('Clic1', adata, expression_counts_adata_norm_knn_norm, expression_counts_adata_norm_knn_random,\n",
    "                     adata_random, expression_counts_adata_random_knn_norm, expression_counts_adata_random_knn_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MID mean, LOW percentage of zeros\n",
    "\n",
    "plot_convolution('Rac2', adata, expression_counts_adata_norm_knn_norm, expression_counts_adata_norm_knn_random,\n",
    "                     adata_random, expression_counts_adata_random_knn_norm, expression_counts_adata_random_knn_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "plot_convolution('Clk4', adata, expression_counts_adata_norm_knn_norm, expression_counts_adata_norm_knn_random,\n",
    "                     adata_random, expression_counts_adata_random_knn_norm, expression_counts_adata_random_knn_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MID-HIGH mean, HIGH percentage of zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_convolution('Meis2', adata, expression_counts_adata_norm_knn_norm, expression_counts_adata_norm_knn_random,\n",
    "                     adata_random, expression_counts_adata_random_knn_norm, expression_counts_adata_random_knn_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MID-HIGH mean, LOW percentage of zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "plot_convolution('Rsrp1', adata, expression_counts_adata_norm_knn_norm, expression_counts_adata_norm_knn_random,\n",
    "                     adata_random, expression_counts_adata_random_knn_norm, expression_counts_adata_random_knn_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HIGH mean, HIGH percentage of zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_convolution('Malat1', adata, expression_counts_adata_norm_knn_norm, expression_counts_adata_norm_knn_random,\n",
    "                     adata_random, expression_counts_adata_random_knn_norm, expression_counts_adata_random_knn_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HIGH mean, LOW percentage of zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "plot_convolution('mt-Co1', adata, expression_counts_adata_norm_knn_norm, expression_counts_adata_norm_knn_random,\n",
    "                     adata_random, expression_counts_adata_random_knn_norm, expression_counts_adata_random_knn_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A caveat with convolution\n",
    "Convolution works fine in single cell datasets, but has a minor issue in some cases. We recall that the convolution on $k$ cells is equivalent to selection of $k$ cells at random. Those cells are chosen with replacement, i.e. a second cell can be chosen again at the $i$th convolution. This should not happen, since once a cell has been chosen for the $k$NN counts, it cannot be chosen again. For example, if there are 100 cells in the dataset and we want to consider the 99NN count distribution, this is simply the sum of counts in all cells. With the convolution, we would get a distribution that can contain more counts that the sum of all counts. \n",
    "\n",
    "Let's imagine an scenario where all cells but one express 3 counts, and one of the cells expresses 50. The 99NN distribution would be 399 + 50 = 297 + 50 = 347. However, when doing the convolution, we can randomly choose 100 times the cell that expresses 50, and have an expression of 5000. \n",
    "\n",
    "This scenario, however, is strange in the single cell datasets, because of the high number of cells and, more importantly, because $k$ is proportional tu the square root of the number of cells. For this number of neighbors, that effect is mitigated, and the convolution is almost identical to the expected distribution.\n",
    "\n",
    "To show that effect we will run a simulation on $n$ cells with $c$ counts, that can follow either a binomial or a negatie binomial distribution. We will plot the difference between the convolution and the expected distribution for a certain range of $k$ cells. The expected distribution will be samples by selecting $X$ random choices of $k$ cells and finding the sum of counts. \n",
    "\n",
    "For a binomial $B(n, 1/c)$ the convolution is $B(kn, 1/c)$; and for a Gamma $NB(n, 1/c)$ is $NB(kn, 1/c)$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "import os\n",
    "\n",
    "def find_BW(x):\n",
    "    return 0.1 * np.mean(x) ** 0.5\n",
    "\n",
    "def plot_conv_comparison(n, c, list_k, X, dist):\n",
    "    fig, axs = plt.subplots(3, 1, figsize=(9, 2), sharex=True, sharey=False)\n",
    "    \n",
    "    if dist == 'B':\n",
    "        counts = np.random.binomial(n, 1/c, size=c)\n",
    "    elif dist == 'NB':\n",
    "        counts = np.random.negative_binomial(n, 1/c, size=c)\n",
    "    \n",
    "    for k in tqdm(list_k):\n",
    "        if dist == 'B':\n",
    "            conv = np.random.binomial(k*n, 1/c, size=X)\n",
    "        elif dist == 'NB':\n",
    "            conv = np.random.negative_binomial(k*n, 1/c, size=X)\n",
    "        \n",
    "        knn_counts = []\n",
    "        for i in range(X):\n",
    "            knn_counts.append(np.sum(counts[np.random.choice(np.arange(len(counts)), k, replace=False)]))\n",
    "        \n",
    "        kde_conv = KernelDensity(bandwidth=find_BW(conv), kernel='gaussian')\n",
    "        kde_conv.fit(conv[:, None])\n",
    "        y_conv = 10**kde_conv.score_samples(np.linspace(min(conv), max(conv), 100)[:, None])\n",
    "\n",
    "        kde_knn_counts = KernelDensity(bandwidth=find_BW(np.array(knn_counts)), kernel='gaussian')\n",
    "        kde_knn_counts.fit(np.array(knn_counts)[:, None])\n",
    "        y_knn_counts = 10**kde_knn_counts.score_samples(np.linspace(min(knn_counts), max(knn_counts), 100)[:, None])\n",
    "        \n",
    "        axs[0].plot(np.linspace(min(conv), max(conv), 100), y_conv/np.max(y_conv))\n",
    "        axs[2].plot(np.linspace(min(knn_counts), max(knn_counts), 100), y_knn_counts/np.max(y_knn_counts))\n",
    "        axs[1].plot([np.mean(knn_counts), np.mean(conv)], [0, 1])\n",
    "        \n",
    "    axs[1].plot([np.sum(counts), np.sum(counts)], [0, 1], c='#000000', )\n",
    "    plt.suptitle(f'Convolution [up] VS real kNN distribution [down] for {c} cells and {n} reads (blue is sqrt(c))')\n",
    "    os.makedirs(os.getcwd() + '/figures/intro_figs/', exist_ok=True)\n",
    "    plt.savefig(os.getcwd() + f'/figures/intro_figs/{n}_{c}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 5000\n",
    "plot_conv_comparison(int(0.05 * c), c, list_k=[int(c ** 0.5)] + [int(k * c) for k in [0.05, 0.1, 0.2, 0.5, 0.7, 0.9, 0.99]] , X=5000, dist='B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 2000\n",
    "plot_conv_comparison(int(2 * c), c, list_k=[int(c ** 0.5)] + [int(k * c) for k in [0.05, 0.1, 0.2, 0.5, 0.7, 0.9, 0.99]] , X=15000, dist='B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 2000\n",
    "plot_conv_comparison(int(0.05 * c), c, list_k=[int(c ** 0.5)] + [int(k * c) for k in [0.05, 0.1, 0.2, 0.5, 0.7, 0.9, 0.99]] , X=15000, dist='B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 2000\n",
    "plot_conv_comparison(int(0.01 * c), c, list_k=[int(c ** 0.5)] + [int(k * c) for k in [0.05, 0.1, 0.2, 0.5, 0.7, 0.9, 0.99]] , X=15000, dist='B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 500\n",
    "plot_conv_comparison(int(0.5 * c), c, list_k=[int(c ** 0.5)] + [int(k * c) for k in [0.05, 0.1, 0.2, 0.5, 0.7, 0.9, 0.99]] , X=15000, dist='B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correcting for non-random kNN in random datasets\n",
    "\n",
    "When calculating the distribution with the convolution, two assumptions are made. First, reads are randomly distributed across cells. Second, the kNN are chosen at random (in this case it would be nicer to say k random cells instead of random kNN, but we will stick to that definition). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_sample(n_cells, n_genes):\n",
    "    knn = int((n_cells ** 0.5))\n",
    "\n",
    "    xoxo = create_random_count_matrix(n_cells = n_cells, n_genes = n_genes, \n",
    "                                      n_min_reads = int(0.01 * n_cells), n_max_reads = int(300 * n_cells))\n",
    "\n",
    "    print('knn_random')\n",
    "    knn_indices_random = return_knn_indices(xoxo, knn=knn, return_random=True) \n",
    "    print('knn')\n",
    "    knn_indices = return_knn_indices(xoxo, knn=knn, return_random=False) \n",
    "\n",
    "    ray.init(ignore_reinit_error=True)\n",
    "    print('c')\n",
    "    list_idx_genes = np.arange(n_genes)\n",
    "    obj_ids = ray.get([return_expression_info_per_gene.remote(gene_idx=list_idx_genes[i], \n",
    "                                adata_X=xoxo, knn_indices=knn_indices, zero_counts=False,\n",
    "                                                            fill_zeros=False) for i in range(len(list_idx_genes))])\n",
    "    print('v')\n",
    "    obj_ids_random = ray.get([return_expression_info_per_gene.remote(gene_idx=list_idx_genes[i], \n",
    "                                adata_X=xoxo, knn_indices=knn_indices_random, zero_counts=False, \n",
    "                                                                    fill_zeros=False) for i in \n",
    "                              range(len(list_idx_genes))])\n",
    "    ray.shutdown()\n",
    "    \n",
    "    return xoxo, obj_ids, obj_ids_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matrix, obj_ids, obj_ids_random = create_random_sample(1000, 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 990\n",
    "print(knn)\n",
    "counts_idx = matrix[:, idx]\n",
    "counts_knn = obj_ids[idx]\n",
    "counts_knn_random = obj_ids_random[idx]\n",
    "\n",
    "\n",
    "x_counts, y_counts = np.unique(counts_idx, return_counts=True)\n",
    "d_c = sts.rv_discrete(a=0, b=len(counts_idx), values=(x_counts, y_counts/sum(y_counts)))\n",
    "distribution_corrected, _ = apply_convolution_read_counts(d_c, knn = knn, threshold = 1, correct=True)\n",
    "\n",
    "range_ax = np.arange(int(0.9 * min(counts_knn)), int(1.1 * max(counts_knn)))\n",
    "\n",
    "_ = plt.hist(counts_knn.tolist(), density=True, bins=int(max(counts_knn) - min(counts_knn)), alpha=0.8, \n",
    "            label='non-random')\n",
    "_ = plt.hist(counts_knn_random.tolist(), density=True, bins=int(max(counts_knn_random) - min(counts_knn_random)), alpha=0.8, \n",
    "            label='random')\n",
    "\n",
    "plt.legend()\n",
    "plt.plot(range_ax + 0.5, distribution_corrected.pmf(range_ax), label='corrected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T11:20:02.091983Z",
     "start_time": "2020-02-08T11:16:23.175Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T11:20:02.094099Z",
     "start_time": "2020-02-08T11:16:23.973Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.clustermap(cosine_similarity(adata_random.X[::10, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "sns.clustermap(np.log10(adata_random.X[::10, ::20] + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "x = pd.Series(adata_random.X[:, :].sum(1), name = \"n counts per cell\")\n",
    "sns.distplot(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "**NOTE**\n",
    "\n",
    "We have seen that the distribution of $X_N$ (or $X^*_N$ if we want to be more correct) is the number of reads found in $N$ cells. There is a caveat: technically, $X_i$ should consider that $i-1$ cells are absent from the dataset, since they have already be taken (their counts have already be summed to the total), and thus the convolution should not consider those cells. However, this drastically increases the computation, since we have to consider the convolution after removing all combinations of $i$ cells. For big $N$ this might be a problem, but for small $N$, which is the case ($N \\sim \\sqrt{C}$), the convolution is a fair approximation to the real distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Wasserstein distance on all genes\n",
    "In this section we will apply the knowledge gathered from previous sections to compute the Wasserstein distance in all genes from the Neuron 10k dataset to see which genes are selected by this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "adata = neurons_10k_adata.copy()\n",
    "list_genes = adata.var_names.values\n",
    "knn = int(0.5 * adata.X.shape[0] ** 0.5)\n",
    "N = len(adata.var_names) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_indices_adata_norm_knn_norm = return_knn_indices(adata.X, knn=knn, return_random=False) \n",
    "expression_counts_adata_norm_knn_norm, categories = return_expression_info(list_genes[:N], adata, \n",
    "                                                                           knn_indices_adata_norm_knn_norm, \n",
    "                                                           category_name = 0)\n",
    "\n",
    "\n",
    "knn_indices_adata_norm_knn_random = return_knn_indices(adata.X, knn=knn, return_random=True) \n",
    "expression_counts_adata_norm_knn_random, categories = return_expression_info(list_genes[:N], adata, \n",
    "                                                                           knn_indices_adata_norm_knn_random, \n",
    "                                                           category_name = 0)\n",
    "\n",
    "\n",
    "\n",
    "adata_random = random_neurons10k_adata.copy()\n",
    "knn = int(0.5 * adata.X.shape[0] ** 0.5)\n",
    "knn_indices_adata_random_knn_norm = return_knn_indices(adata_random.X, knn=knn, return_random=False) \n",
    "expression_counts_adata_random_knn_norm, categories = return_expression_info(list_genes[:N], adata_random, \n",
    "                                                                           knn_indices_adata_random_knn_norm, \n",
    "                                                           category_name = 0)\n",
    "\n",
    "\n",
    "knn_indices_adata_random_knn_random = return_knn_indices(adata_random.X, knn=knn, return_random=True) \n",
    "expression_counts_adata_random_knn_random, categories = return_expression_info(list_genes[:N], adata_random, \n",
    "                                                                           knn_indices_adata_random_knn_random, \n",
    "                                                           category_name = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def compute_convs(adata, adata_random, gene, \n",
    "                 expression_counts_adata_norm_knn_norm, \n",
    "                 expression_counts_adata_norm_knn_random,\n",
    "                 expression_counts_adata_random_knn_norm, \n",
    "                 expression_counts_adata_random_knn_random,):\n",
    "    \n",
    "    counts_gene = adata[:, gene].X.ravel()\n",
    "    x_counts, y_counts = np.unique(counts_gene, return_counts=True)\n",
    "    d_c = sts.rv_discrete(a=0, b=len(counts_gene), values=(x_counts, y_counts/sum(y_counts)))\n",
    "    convolution, _ = apply_convolution_read_counts(d_c, knn=knn, threshold = 1)\n",
    "    \n",
    "    \n",
    "    counts_gene_random = adata_random[:, gene].X.ravel()\n",
    "    x_counts_random, y_counts_random = np.unique(counts_gene_random, return_counts=True)\n",
    "    d_c_random = sts.rv_discrete(a=0, b=len(counts_gene_random), values=(x_counts_random, y_counts_random/sum(y_counts_random)))\n",
    "    convolution_random, _ = apply_convolution_read_counts(d_c_random, knn=knn, threshold = 1)\n",
    "    \n",
    "    \n",
    "    EMD_N_N = EMD(expression_counts_adata_norm_knn_norm[gene], convolution) \n",
    "    EMD_N_R = EMD(expression_counts_adata_norm_knn_random[gene], convolution)\n",
    "    EMD_R_N = EMD(expression_counts_adata_random_knn_norm[gene], convolution_random)\n",
    "    EMD_R_R = EMD(expression_counts_adata_random_knn_random[gene], convolution_random)\n",
    "    \n",
    "    return EMD_N_N, EMD_N_R, EMD_R_N, EMD_R_R\n",
    "\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "\n",
    "adata_obj = ray.put(adata)\n",
    "adata_random_obj = ray.put(adata_random)\n",
    "expression_counts_adata_norm_knn_norm_id = ray.put(expression_counts_adata_norm_knn_norm)\n",
    "expression_counts_adata_norm_knn_random_id = ray.put(expression_counts_adata_norm_knn_random)\n",
    "expression_counts_adata_random_knn_norm_id = ray.put(expression_counts_adata_random_knn_norm)\n",
    "expression_counts_adata_random_knn_random_id = ray.put(expression_counts_adata_random_knn_random)\n",
    "\n",
    "ray_obj_ids = [compute_convs.remote(adata_obj, adata_random_obj, gene, \n",
    "                                     expression_counts_adata_norm_knn_norm_id, \n",
    "                                     expression_counts_adata_norm_knn_random_id,\n",
    "                                     expression_counts_adata_random_knn_norm_id, \n",
    "                                     expression_counts_adata_random_knn_random_id,\n",
    "                                   ) for gene in list_genes[:N]]\n",
    "ray_objs = ray.get(ray_obj_ids)\n",
    "\n",
    "\n",
    "list_D_adata_knn, list_D_adata_knn_random, list_D_adata_random_knn, list_D_adata_random_knn_random = [], [], [], []\n",
    "\n",
    "list_D_adata_knn = [x[0] for x in ray_objs]\n",
    "list_D_adata_knn_random = [x[1] for x in ray_objs]\n",
    "list_D_adata_random_knn = [x[2] for x in ray_objs]\n",
    "list_D_adata_random_knn_random = [x[3] for x in ray_objs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'x': [0]*len(list_genes[:N])+[1]*len(list_genes[:N])+[2]*len(list_genes[:N])+[3]*len(list_genes[:N]) , \n",
    "                   'y': list_D_adata_knn + list_D_adata_knn_random + list_D_adata_random_knn + list_D_adata_random_knn_random})\n",
    "\n",
    "\n",
    "sns.swarmplot(x='x', y='y', data=df.loc[np.random.choice(np.arange(4*N), 1000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_mean_exp, list_p_zeros = return_mean_per(adata[:, list_genes[:N]].X)\n",
    "df_bokeh = pd.DataFrame({'m': np.log10(list_mean_exp), 'z': list_p_zeros, 'n': list_genes[:N], \n",
    "                   'd':list_D_adata_knn, \n",
    "                         'p':np.array(list_D_adata_random_knn),\n",
    "                         'r':np.array(list_D_adata_random_knn) / np.array(list_D_adata_knn),\n",
    "                         'e':np.array(list_D_adata_knn) - np.array(list_D_adata_random_knn)})[:2900]\n",
    "\n",
    "df_bokeh = df_bokeh.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "# Uncorrected distances\n",
    "\n",
    "p = figure(tools=\"box_zoom,hover,reset\", plot_height=600, plot_width=600, tooltips=[(\"Gene\",\"@n\"), ('Value', '@d')])\n",
    "\n",
    "color_map = LinearColorMapper(low=min(df_bokeh.d.values), \n",
    "                              high=np.percentile(df_bokeh.d.values, 95), palette='Viridis256')\n",
    "\n",
    "\n",
    "p.scatter('m', 'z', source=df_bokeh, fill_color={'field': 'd', 'transform':color_map}, \n",
    "          alpha=0.7, line_color=None)\n",
    "\n",
    "from bokeh.models import ColorBar\n",
    "bar = ColorBar(color_mapper=color_map, location=(0,0))\n",
    "p.add_layout(bar, \"left\")\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "# Corrected distances\n",
    "\n",
    "p = figure(tools=\"box_zoom,hover,reset\", plot_height=600, plot_width=600, tooltips=[(\"Gene\",\"@n\"), ('Value', '@e')])\n",
    "\n",
    "color_map = LinearColorMapper(low=min(df_bokeh.d.values), \n",
    "                              high=np.percentile(df_bokeh.d.values, 95), palette='Viridis256')\n",
    "\n",
    "\n",
    "p.scatter('m', 'z', source=df_bokeh, fill_color={'field': 'e', 'transform':color_map}, \n",
    "          alpha=0.7, line_color=None)\n",
    "\n",
    "from bokeh.models import ColorBar\n",
    "bar = ColorBar(color_mapper=color_map, location=(0,0))\n",
    "p.add_layout(bar, \"left\")\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "# Proportion of change (random_dist / uncorrected_dist)\n",
    "\n",
    "p = figure(tools=\"box_zoom,hover,reset\", plot_height=600, plot_width=600, tooltips=[(\"Gene\",\"@n\"), ('Correction proportion', '@r')])\n",
    "\n",
    "color_map = LinearColorMapper(low=min(df_bokeh.r.values), \n",
    "                              high=np.percentile(df_bokeh.r.values, 95), palette='Viridis256')\n",
    "\n",
    "\n",
    "p.scatter('m', 'z', source=df_bokeh, fill_color={'field': 'r', 'transform':color_map}, \n",
    "          alpha=0.7, line_color=None)\n",
    "\n",
    "from bokeh.models import ColorBar\n",
    "bar = ColorBar(color_mapper=color_map, location=(0,0))\n",
    "p.add_layout(bar, \"left\")\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "for i in tqdm(range(0, len(list_mean_exp), 10)):\n",
    "    x = np.log10(list_mean_exp)[i]\n",
    "    y0 = np.array(list_D_adata_random_knn)[i]\n",
    "    yf = np.array(list_D_adata_knn)[i]\n",
    "    \n",
    "    plt.plot([x,x], [np.log10(y0+1), np.log10(yf+1)], \n",
    "             c='#ababab', linewidth=1, alpha=0.01)\n",
    "    \n",
    "    plt.scatter(x, np.log10(y0+1), c='#007ab7', s=5, alpha=0.8)\n",
    "    plt.scatter(x, np.log10(yf+1), c='#c62d42', s=5, alpha=0.8)\n",
    "\n",
    "plt.xlabel('log$_{10}$(mean expression)')\n",
    "plt.ylabel('log$_{10}$(Wasserstein distance + 1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_ratios = np.array(list_D_adata_random_knn) / np.array(list_D_adata_knn)\n",
    "arr_ratios[arr_ratios > 1] = 1\n",
    "plt.scatter(np.log10(list_mean_exp), arr_ratios, )\n",
    "\n",
    "plt.xlabel('log$_{10}$(mean expression)')\n",
    "plt.ylabel('log$_{10}$(Wasserstein distance + 1)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The genes with highest difference in distance fall in two categories.\n",
    "* Genes with low expression and low percentage of low percentage of ceros. Their distributions fit the expected ones (their distance thus is small), and the distribution with the random adata has a small deviation from the expected one. Those cases are uninteresting because they are already genes with low expression and with no kNN expression.\n",
    "* Genes with high expression (top 5%), and where the expected kNN read distribution from the randomized adata differs with the real one. We will see that those cases will not be considered as HVG,and this difference can somewhat be disregarded. Nontheless, it can be interesting to consider it just in case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene = 'Foxp2'\n",
    "plot_convolution(gene, adata, expression_counts_adata_norm_knn_norm, expression_counts_adata_norm_knn_random,\n",
    "                     adata_random, expression_counts_adata_random_knn_norm, \n",
    "                 expression_counts_adata_random_knn_random)\n",
    "\n",
    "sum_counts = np.zeros(len(adata))\n",
    "sum_counts[adata[:, gene].X.flatten() > 0] = expression_counts_adata_norm_knn_norm[gene]\n",
    "adata.obs['knn'] = sum_counts\n",
    "\n",
    "\n",
    "sc.pl.umap(adata, color=[gene, 'knn'], cmap=magma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select best genes\n",
    "Now that all scores have been calculated, we are going to select the genest with the highest distance. For that we plot the mean (X) and the distance(Y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substract_median(x, y, n_windows=15):\n",
    "    linspace = np.linspace(min(x), max(x), n_windows+1)\n",
    "    y_adjust = y.copy()\n",
    "    \n",
    "    for i in range(n_windows):\n",
    "        mask = (x >= linspace[i]) & (x <= linspace[i+1])\n",
    "        y_adjust[mask] -= np.median(y[mask])\n",
    "        \n",
    "    return y_adjust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bokeh = pd.DataFrame({\n",
    "    'm': np.log10(list_mean_exp), \n",
    "    'z': list_p_zeros, \n",
    "    'n': list_genes[:N], \n",
    "    'd': list_D_adata_knn, \n",
    "    'e': np.array(list_D_adata_knn) - np.array(list_D_adata_random_knn), \n",
    "    })[:]\n",
    "\n",
    "df_bokeh['e_correct'] = substract_median(df_bokeh['m'].values, df_bokeh['e'].values, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot on the left shows the corrected distances with respect to their mean. Interestingly, the genes with highest mean have a non-zero distance, but also no variation. To correct that skewness, we are going to \n",
    "*normalize* the distance to a baseline level. This baseline level will be calculated by calculated the median distance across a window of mean of expressions. \n",
    "\n",
    "In this way we will keep genes with distances above a baseline level, which are the interesting ones. This *normalized* plot the one on the right.\n",
    "\n",
    "This correction is explained more thoroughly with other datasets either artificial or biological on `3_Why_applying_median_correction_is_a_good_option.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "p = figure(tools=\"box_zoom,hover,reset\", plot_height=400, plot_width=400, tooltips=[(\"Gene\",\"@n\"), ('Value', '@e')])\n",
    "\n",
    "p.scatter('m', 'e', source=df_bokeh,  alpha=0.7, line_color=None)\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "p = figure(tools=\"box_zoom,hover,reset\", plot_height=400, plot_width=400, tooltips=[(\"Gene\",\"@n\"), ('Value', '@e')])\n",
    "\n",
    "p.scatter('m', 'e_correct', source=df_bokeh,  alpha=0.7, line_color=None)\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to select the genes with highest distance. This can be chosen arbitrarily (select the N highest values), or by finding a inflexion point. This inflexion point could be interpreted as the point where the density of points, mapped to the Y-axis, increases. To calculate the cutoff, we are going to plot a rank of the distances (from lowest to highest) VS the distance. This curve has the common hockey-stick shape, and to calculate the *curving point* we are going to select the point of the curve with highest distance to the straight line that joins the two extremes on the curve.\n",
    "\n",
    " The distance between the straight line and a point $(u, v)$ con the curve can be expressed as the following optimization problem. Given the straight line with coordinates $(x, mx + b)$, the distance between $(u, v)$ and the line is the distance to the point $(x, mx+b)$ that minimizes its distance. If we consider the square of the distance, to simplify the problem, the optimal point $(x_{opt}, mx_{opt} + b)$ is\n",
    " \n",
    " $$x_{opt} = \\frac{u - mb + mv}{1+m^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "# we are going to select the best genes, which are located at the inflexion point in that curve\n",
    "\n",
    "def get_cutoff_curve(y, S = 0.1):\n",
    "    # Plots a curve, and finds the best point by joining the extremes of the curve with a line, and selecting\n",
    "    # the point from the curve with the greatest distance.\n",
    "    # The distance between a point in a curve, and the straight line is set by the followin equation\n",
    "    # if u,v is the point in the curve, and y = mx + b is the line, then\n",
    "    # x_opt = (u - mb + mv) / (1 + m^2)\n",
    "    \n",
    "    plt.plot(np.arange(len(y)), np.sort(y))\n",
    "    \n",
    "    min_y, max_y = np.min(y), np.max(y)\n",
    "    m, b = (max_y - min_y) / len(y), min_y\n",
    "    \n",
    "    list_d = []\n",
    "    \n",
    "    for u, v in enumerate(np.sort(y)):\n",
    "        x_opt = (u - m * b + m * v) / (1 + m ** 2)\n",
    "        y_opt = x_opt * m + b\n",
    "        d = (x_opt - u) ** 2 + (y_opt - v) ** 2\n",
    "        \n",
    "        list_d.append(d)\n",
    "\n",
    "    \n",
    "    # S is a corrector factor. It leverages the best value in the curve, and selects a more or less stringent\n",
    "    # value in the curve. the maximum distance is multiplied by (1 - S), and the leftmost or rightmost index\n",
    "    # is selected\n",
    "    \n",
    "    dist_S = (1 - np.abs(S)) * np.max(list_d)\n",
    "    S_idx = np.argwhere(list_d >= dist_S)\n",
    "    \n",
    "    if S >= 0:\n",
    "        max_d_idx = np.max(S_idx)\n",
    "    if S < 0:\n",
    "        max_d_idx = np.min(S_idx)\n",
    "        \n",
    "    plt.scatter(max_d_idx, np.sort(y)[max_d_idx])\n",
    "    \n",
    "    plt.xlabel(\"Rank of genes by Wasserstein distance\")\n",
    "    plt.ylabel(\"Wasserstein distance\")\n",
    "    \n",
    "    return np.sort(y)[max_d_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When implementing the algorithm to calculate the cutoff point, we have added the parameter $S$, $0 < |S| < 1$, which allows to adjust that cutoff point to choose fewer or more genes. If $D$ is the highest distance between the straight line and the curve, we calculate the *new* distance as $D\\cdot |S|$. If $S > 0$, then we will select the point highest on the rank such that its distance is greater than $D\\cdot |S|$, thus selecting fewer genes. Vice-versa if $S < 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cutoff = get_cutoff_curve(df_bokeh['e_correct'].values, S=-0.025)    \n",
    "df_bokeh['color'] = [\"#ababab\" if y < y_cutoff else \"#007ab7\" for y in df_bokeh['e_correct'].values]\n",
    "print(y_cutoff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the left, the selected genes before correcting for baseline; and on the right after correcting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "p = figure(tools=\"box_zoom,hover,reset\", plot_height=400, plot_width=400, tooltips=[(\"Gene\",\"@n\"), ('Value', '@e')])\n",
    "\n",
    "color_map = LinearColorMapper(low=min(df_bokeh.d.values), \n",
    "                              high=np.percentile(df_bokeh.d.values, 90), palette='Viridis256')\n",
    "\n",
    "\n",
    "p.scatter('m', 'e', source=df_bokeh,  \n",
    "          alpha=0.7, line_color=None, \n",
    "         color='color')\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "p = figure(tools=\"box_zoom,hover,reset\", plot_height=400, plot_width=400, tooltips=[(\"Gene\",\"@n\"), ('Value', '@e')])\n",
    "\n",
    "color_map = LinearColorMapper(low=min(df_bokeh.d.values), \n",
    "                              high=np.percentile(df_bokeh.d.values, 90), palette='Viridis256')\n",
    "\n",
    "\n",
    "p.scatter('m', 'e_correct', source=df_bokeh, \n",
    "          alpha=0.7, line_color=None, \n",
    "         color='color')\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Points mapped to the curve of percentage of zeros VS mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = figure(tools=\"box_zoom,hover,reset\", plot_height=400, plot_width=400, tooltips=[(\"Gene\",\"@n\"), ('Value', '@e')])\n",
    "\n",
    "color_map = LinearColorMapper(low=min(df_bokeh.d.values), \n",
    "                              high=np.percentile(df_bokeh.d.values, 90), palette='Viridis256')\n",
    "\n",
    "p.scatter('m', 'z', source=df_bokeh, fill_color='color', alpha=0.7, line_color=None)\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_genes_list = df_bokeh['n'][df_bokeh['e_correct'] > y_cutoff].values\n",
    "print('N HVG: {}'.format(len(best_genes_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.layers['raw_counts'] = adata.X.copy()\n",
    "sc.pp.log1p(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "adata.var['highly_variable'] = [g in best_genes_list \n",
    "                               for g in adata.var_names]\n",
    "\n",
    "sc.pp.pca(adata, n_comps=75)\n",
    "sc.pp.neighbors(adata, n_neighbors=knn)\n",
    "sc.tl.leiden(adata, random_state=random_state,\n",
    "            resolution=0.5)\n",
    "sc.tl.umap(adata, random_state=random_state)\n",
    "\n",
    "sc.pl.umap(adata, color='leiden', \n",
    "           legend_loc='on data', \n",
    "           legend_fontsize=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect cells with higher contribution from HVGs\n",
    "\n",
    "When calculating the KNN counts for each gene, we can apply this information to find which cells contribute more to the cell identities which separate the clusters.\n",
    "\n",
    "In order to do that the main strategy is to assign each cell a score, based on the knn counts for each gene. We will study different transformations to adapt the score.\n",
    "\n",
    "So far, we will assume different options:\n",
    "* Each gene is independent\n",
    "* The score for each gene might be either the same or proportional to the Wasserstein distance.\n",
    "* The score for each cell within each gene can be the same for each cell, the original knn counts, or a scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.X = adata.layers['raw_counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expression_counts_adata_norm_knn_norm_with_zeros, categories = return_expression_info(list_genes[:N], adata, \n",
    "                                                                           knn_indices_adata_norm_knn_norm, \n",
    "                                                           category_name = 0, fill_zeros=True)\n",
    "\n",
    "dict_wassers = {df_bokeh['n'].loc[i]: df_bokeh['e_correct'].loc[i] for i in range(len(df_bokeh))} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_knn_score(dict_expression_per_gene, scores_per_gene, gene_list = None, scale_knn_per_gene=True, \n",
    "                  apply_score=True, scale_all_scores=False, log=True):\n",
    "    if gene_list is not None:\n",
    "        dict_expression_per_gene = {k: dict_expression_per_gene[k] for k in gene_list \n",
    "                                    if k in dict_expression_per_gene}\n",
    "        scores_per_gene = {k: scores_per_gene[k] for k in gene_list if k in scores_per_gene}\n",
    "        \n",
    "    array_knn_expression = np.array(list(dict_expression_per_gene.values())).transpose()\n",
    "    \n",
    "    if scale_knn_per_gene:\n",
    "        array_knn_expression /= np.max(array_knn_expression, axis=0)\n",
    "        \n",
    "    if apply_score:\n",
    "        array_knn_expression *= np.array(list(scores_per_gene.values()))\n",
    "    \n",
    "    scores_per_cell = array_knn_expression.sum(1)\n",
    "    \n",
    "    if scale_all_scores:\n",
    "        scores_per_cell /= array_knn_expression.shape[1]\n",
    "    \n",
    "    if log:\n",
    "        scores_per_cell = np.log10(scores_per_cell)\n",
    "    \n",
    "    return scores_per_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['score_per_cell'] = get_knn_score(expression_counts_adata_norm_knn_norm_with_zeros, dict_wassers, \n",
    "                                           scale_all_scores=False, log=True, gene_list = best_genes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var['highly_variable'] = [g in best_genes_list \n",
    "                               for g in adata.var_names]\n",
    "\n",
    "sc.pp.pca(adata, n_comps=75)\n",
    "sc.pp.neighbors(adata, n_neighbors=knn)\n",
    "sc.tl.leiden(adata, random_state=random_state, resolution=0.8)\n",
    "sc.tl.umap(adata, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "\n",
    "sunset = ['#f3e79b','#fac484','#f8a07e','#eb7f86','#ce6693', '#a059a0','#5c53a5']\n",
    "sunsetdark = ['#fcde9c','#faa476','#f0746e','#e34f6f','#dc3977','#b9257a','#7c1d6f']\n",
    "cmap = LinearSegmentedColormap.from_list('custom cmap', sunset[::-1], N=256)\n",
    "cmap.set_bad('#efefef')\n",
    "\n",
    "\n",
    "sc.pl.umap(adata, color=['leiden', 'score_per_cell'], legend_loc='on data', frameon=False, \n",
    "           cmap=cmap, plotnonfinite=True, \n",
    "           vmin = -1, vmax = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adata, color=['leiden', 'Adarb2', 'Alas2', 'Hba-a1', 'Adgre5', 'Nrxn3', 'Maf',\n",
    "                        'Arx', 'Adarb2', 'Mfng', 'Hmgn2', 'Hmgb2', 'H2afz', 'Arpp21', 'Nrcam'], legend_loc='on data', frameon=False, \n",
    "           cmap=cmap, plotnonfinite=True, use_raw=False, ncols=3)\n",
    "print('Adarb2' in best_genes_list, y_cutoff, dict_wassers['Adarb2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.rank_genes_groups(adata, groupby='leiden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.rank_genes_groups_tracksplot(adata, dendrogram=False, n_genes=6, figsize=(17, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:alex-base] *",
   "language": "python",
   "name": "conda-env-alex-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "291px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "802.85px",
    "left": "1578px",
    "right": "20px",
    "top": "92px",
    "width": "313px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
