{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triku stability measures\n",
    "\n",
    "In this notebook we will calculate certain stability and robustness measures, that is, we are goin to test certain parameters in triku and see how different the selected genes are.\n",
    "\n",
    "The main measurements to take into account will be **PCA number of components**, and **knn**; since those two components end up taking a bunch of computation time. By default PCA components are set to 25 and knn is set to $0.5\\sqrt{n_{cells}}$. For large datasets (> 20k cells), the processing can take a couple of minutes (assuming parallel processing, else it takes ~ 4 minutes), mainly because of the calculation of PCA and knn indices. Also, calculation of distances using the **randomized matrix** doubles the time amount, because all steps have to be repeated using the randomized matrix. \n",
    "\n",
    "Thus, in this step we are going to see how each of those variables affects the number of selected genes. To do that we will use a set of benchmarking dataset by Mereu et al. The datasets are PBMC from human and colon cells from mouse, with different library preparation methods: Chromium, CEL-seq, SMART-seq2, QUARTZ-seq, InDrop, ddSEQ, and snChromium. The dataset is interesting to study stability across different library preparation methods, but also considering two different organisms and tissues. We will also include artificial datasets to include a ground truth when it is necessary.\n",
    "\n",
    "There is another dataset, from Ding et al. with a similar benchmark, which is also included here, in this dataset they apply Smart-seq2, CEL-seq2, 10x chromium (V2 and V3), Drop-seq, Seq-well, inDrops, sci-RNAseq. They share 10x, Smart-seq2, CEL-seq (not version), inDrops. We should then have a fair set of datasets to apply comparisons to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import triku as tk\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bokeh.io import show, output_notebook, reset_output\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models import LinearColorMapper\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import product\n",
    "\n",
    "reset_output()\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.getcwd() + '/code')\n",
    "\n",
    "# Selection of palettes for cluster coloring, and scatter values\n",
    "from triku_nb_code.palettes_and_cmaps import magma, bold_and_vivid\n",
    "from triku_nb_code.robustness_functions import run_all_batches\n",
    "from triku_nb_code.robustness_functions import run_batch, random_noise_parameter, plot_scatter_parameter, compare_parameter, \\\n",
    "get_all_pics_dataset, plot_scatter_datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.getcwd() + '/exports/robustness/', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.dirname(os.getcwd()) + '/data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# csv generation\n",
    "To do the analysis across conditions, we will generate all possible combinations, and later on do the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_dir = os.getcwd() + '/exports/robustness/'\n",
    "read_dir = data_dir + 'Mereu_2020/'\n",
    "\n",
    "lib_preps = ['SingleNuclei', 'Dropseq', 'inDrop', '10X', 'SMARTseq2', 'CELseq2', 'QUARTZseq']\n",
    "orgs = ['mouse', 'human'] \n",
    "\n",
    "run_all_batches(lib_preps, orgs, 'mereu', read_dir, save_dir) # Uncomment to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_dir = os.getcwd() + '/exports/robustness/'\n",
    "read_dir = data_dir + 'Ding_2020/'\n",
    "\n",
    "lib_preps = ['10X', 'CELseq2', 'Dropseq', 'inDrop', 'sci-RNAseq', 'Seq-Well', 'SingleNuclei', 'SMARTseq2']\n",
    "orgs = ['human', 'mouse']\n",
    "\n",
    "run_all_batches(lib_preps, orgs, 'ding', read_dir, save_dir)  # Uncomment to run!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robustness based on seed\n",
    "Many of the parts from triku require a random seed: PCA calculation (because we use the randomized variant), nearest neighbor calculation, and random matrix generation. Each of those processes interfere with the distances we obtain, either the ones from the original datasets, or the ones from the randomized dataset. Due to that, we have to evaluate this noise, and see how it might affect the genes that are given, even without considering the randomisation.\n",
    "\n",
    "To do that we will study which of the variables affect, or enhance, the noise: kNN calculation, PCA, or dataset randomization (number of windows is not stochastic, so it won't be a factor). To see the effect, we will do two types of plots: variability evaluation, and limit of features achievable given the level of noise.\n",
    "\n",
    "For the first type of plot we will fix a variable and evaluate a range of the other variables (fix kNN and evaluate number of components, and vice-versa). If, for example, we fix kNN, for each of the possible number of components, we will take pairs of dataframes (combinations of two seeds), and compare their corrected and uncorrected distance together. \n",
    "\n",
    "How do we do the comparison: if $d_A$ is a distance from df with seed A, and $d_B$ is the distance in the same gene for B, then the comparison value is: \n",
    "\n",
    "$$\\frac{|d_A - d_B|}{|d_A| + |d_B|}$$\n",
    "\n",
    "This value is range between 0 ($d_A = d_B$) and 1 ($d_A$ and $d_B$ have opposite signs).\n",
    "\n",
    "We plot a swarmplot with three categories: the first 250 features (based on highest distance), 1000 and 5000 features. We should expect less noise on the first features, because they are the ones with more distance. Also, for each option in the swarmplot, the column on the **left are distances without randomization** and the column on the **right are distances with randomization**. We should expect higher noise on distances with randomization, because the random noise from the randomized dataset is highger then the one from the non-randomized one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_random = False  # Set to True to see the two column layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET ORG, DATASET AND LIB_PREP TO CREATE FIGURES!\n",
    "# lib_prep, org, dataset = '10X', 'mouse', 'ding'\n",
    "lib_prep, org, dataset = '10X', 'mouse', 'mereu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "df_0_250 = random_noise_parameter(lib_prep, org, dataset, save_dir, 0, 250, what='relative noise', by='knn')\n",
    "df_250_1000 = random_noise_parameter(lib_prep, org, dataset, save_dir, 250, 1000, what='relative noise', by='knn')\n",
    "df_1000_5000 = random_noise_parameter(lib_prep, org, dataset, save_dir, 1000, 5000, what='relative noise', by='knn')\n",
    "\n",
    "# Remember: left = non randomized - right = randomized\n",
    "plot_scatter_parameter(\n",
    "    [df_1000_5000, df_250_1000, df_0_250], \n",
    "    ['1000 - 5000', '250 - 1000', '0 - 250'], \n",
    "    lib_prep, org, dataset, by='knn', \n",
    "    title='Noise_distance_based_on_seed,_kNN', ylabel=\"$\\\\frac{|d_A-d_B|}{|d_A| + |d_B|}$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "df_0_250 = random_noise_parameter(lib_prep, org, dataset, save_dir, 0, 250, what='relative noise', by='pca')\n",
    "df_250_1000 = random_noise_parameter(lib_prep, org, dataset, save_dir, 250, 1000, what='relative noise', by='pca')\n",
    "df_1000_5000 = random_noise_parameter(lib_prep, org, dataset, save_dir, 1000, 5000, what='relative noise', by='pca')\n",
    "\n",
    "# Remember: left = non randomized - right = randomized\n",
    "plot_scatter_parameter([df_1000_5000, df_250_1000, df_0_250], \n",
    "                        ['1000 - 5000', '250 - 1000', '0 - 250'], \n",
    "                       lib_prep, org, dataset, by='pca',\n",
    "                      title='Noise_distance_based_on_seed,_PCA', ylabel=\"$\\\\frac{|d_A-d_B|}{|d_A| + |d_B|}$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For kNN we see that there is generally a sweet spot between $\\sqrt{N}/2$ and 2$\\sqrt{N}$, with smaller variation in the distances without randomization. As for PCA components, we see that, interestingly, seed noise increases with the number of PCA components. Although paradoxical, it makes sense: first components are less prone to ve variable, and thus it is more difficult to experience noise. In fact, if we consider 3 components, the noise is almost 0 in the non-randomized set of distances, which tells us that the noise in the randomized set of distances arises mainly due to dataset randomization. However, although the noise is small, it does not mean that the selected features are the correct ones! Fewer components means less information from the datasets. We'll see that when we compare festures across components, later on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next plots we will consider directly the overlapping between features. For each set of features within an overlap range, we will see the percentage of overlap between those features. That is, for example, for kNN = $\\sqrt{N}$ and 100 PCA components, compare the first 250 features between seed 0 and seed 1. Instead of considering features 250 - 1000 and 1000 - 5000, we will consider features 0 - 1000 and 0 - 5000 directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "df_0_250 = random_noise_parameter(lib_prep, org, dataset, save_dir, 0, 250, what='overlap', by='knn')\n",
    "df_0_1000 = random_noise_parameter(lib_prep, org, dataset, save_dir, 0, 1000, what='overlap', by='knn')\n",
    "df_0_5000 = random_noise_parameter(lib_prep, org, dataset, save_dir, 0, 5000, what='overlap', by='knn')\n",
    "\n",
    "# Remember: left = non randomized - right = randomized\n",
    "plot_scatter_parameter([df_0_5000, df_0_1000, df_0_250], \n",
    "   ['0 - 5000', '0 - 1000', '0 - 250'],\n",
    "    lib_prep, org, dataset, step=1, by='knn',\n",
    "        palette = 'sunsetmid3',\n",
    "        title='Overlap_of_features_based_on_seed,_kNN', ylabel=\"Overlap\", \n",
    "                       plot_random=plot_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "df_0_250 = random_noise_parameter(lib_prep, org, dataset, save_dir, 0, 250, what='overlap', by='pca')\n",
    "df_0_1000 = random_noise_parameter(lib_prep, org, dataset, save_dir, 0, 1000, what='overlap', by='pca')\n",
    "df_0_5000 = random_noise_parameter(lib_prep, org, dataset, save_dir, 0, 5000, what='overlap', by='pca')\n",
    "\n",
    "# Remember: left = non randomized - right = randomized\n",
    "plot_scatter_parameter([df_0_5000, df_0_1000, df_0_250], \n",
    "            ['0 - 5000', '0 - 1000', '0 - 250'], lib_prep, org, dataset,\n",
    "            step=1, palette = 'sunsetmid3', \n",
    "            by='pca', title='Overlap_of_features_based_on_seed,_PCA', ylabel=\"Overlap\",\n",
    "                       plot_random=plot_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a similar trend than in the previous case: low kNN values can be detrimental to the quality of feature selection, although the effect is resolved with a number of kNN between $\\sqrt{N}/2$ and 2$\\sqrt{N}$. Regarding PCA components, there is not much variation, with overlap values higher than 95% at sensible PCA component values near 20-30."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robustness between different parameter values\n",
    "In this section we are going to compare the overlapping percentage of number of features given different parameter values. As in the previous section, we are going to fix:\n",
    "* number of kNN in $\\sqrt{N}$, number of windows in 100 to see changes in PCA components.\n",
    "* number of PCA components in 30, number of windows in 100 to see changes in kNN values.\n",
    "* additionally, we are going to fix the number of PCA components in 30 and number of kNN in $\\sqrt{N}$ to see changes on number of windows for median correction. \n",
    "\n",
    "The strategy in this case will be the same: consider distance values for each of the parametters, and calculate the overlap between the first N features. For example, when comparing kNN values, we are going to compare the values from $\\sqrt{N}$, seed 0 with $2\\sqrt{N}$ seed 1, seed 2, etc. We will also compare $\\sqrt{N}$ with itself, which has already been done, but which will still be useful.\n",
    "\n",
    "We will also apply the Pearson correlation between the distances for the first N features. Pearson correlation, in contrast to overlap of features, will be more robust, but less realiable, because we are interested in the selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "df_violin_0_500 = compare_parameter(lib_prep, org, dataset, save_dir, 0, 500, what='overlap', by='knn')\n",
    "df_violin_0_1000 = compare_parameter(lib_prep, org, dataset, save_dir, 0, 1000, what='overlap', by='knn')\n",
    "df_violin_0_2500 = compare_parameter(lib_prep, org, dataset, save_dir, 0, 2500, what='overlap', by='knn')\n",
    "df_violin_0_5000 = compare_parameter(lib_prep, org, dataset, save_dir, 0, 5000, what='overlap', by='knn')\n",
    "\n",
    "# Remember: left = non randomized - right = randomized\n",
    "plot_scatter_parameter([df_violin_0_5000, df_violin_0_2500, df_violin_0_1000, df_violin_0_500], \n",
    "   ['0 - 5000',  '0 - 2500', '0 - 1000', '0 - 500'], \n",
    "    lib_prep, org, dataset, step=1, palette = 'sunsetmid4', by='knn',\n",
    "        title='kNN_robustness,_overlap', ylabel=\"Overlap\", plot_random=plot_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "df_violin_0_500 = compare_parameter(lib_prep, org, dataset, save_dir, 0, 500, what='correlation', by='knn')\n",
    "df_violin_0_1000 = compare_parameter(lib_prep, org, dataset, save_dir, 0, 1000, what='correlation', by='knn')\n",
    "df_violin_0_2500 = compare_parameter(lib_prep, org, dataset, save_dir, 0, 2500, what='correlation', by='knn')\n",
    "df_violin_0_5000 = compare_parameter(lib_prep, org, dataset, save_dir, 0, 5000, what='correlation', by='knn')\n",
    "\n",
    "# Remember: left = non randomized - right = randomized\n",
    "plot_scatter_parameter([df_violin_0_5000, df_violin_0_2500, df_violin_0_1000, df_violin_0_500], \n",
    "   ['0 - 5000',  '0 - 2500', '0 - 1000', '0 - 500'], \n",
    "    lib_prep, org, dataset, step=1, \n",
    "    palette = 'sunsetmid4', by='knn',\n",
    "    title='kNN_robustness,_correlation', \n",
    "    ylabel='Pearson correlation', plot_random=plot_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a general trend across datasets: overlap across kNN values decreases quite rapidly, so kNN is a sensitive parameter to choose. Generally, values between $\\sqrt{N}/2$ and $\\sqrt{N}$ have similar overlaps (70-80% in worst case scenario). The overlaps with larger knn values, interestingly, decreases more rapidly. This might be because, since many of the features of interest have a lower expression as a whole, or more concentrated across datasets, such a high kNN value can imply a selection of cells larger than the original number of cells of interest for a interesting feature, and therefore the kNN expression for the cells of interest is mixed with noise from cells that are not that interesting. \n",
    "\n",
    "For example, if a population in a 10000 cell dataset has 150 cells with a characteristic expression pattern, using $5\\sqrt{N} = 500$ cells will include zero or noisy counts from 350 cells. Therefore, the kNN expression will be noisier and the features will not be selected as wells as with k = $\\sqrt{N} = 100$ cells.\n",
    "\n",
    "Therefore, if you expect a small subpopulation, it might even be better to set $0.5\\sqrt{N}$ as the preferable k. This value is set by default.\n",
    "\n",
    "Generally, for datasets with higher number of detected genes the overlap is greater, around 85-90% between $\\sqrt{N}/2$ and $\\sqrt{N}$. \n",
    "\n",
    "Although it depends on the dataset, there is a general trend that overlaps are smaller for a more reduced number of features, whereas for higher number of features the overlap is greater. I do not know why this might happen. Possibly, there is a range of slected features in the 2000 to 5000 scale that will always be selected because the rest is expression noise, or much less defined genes, that is, genes with much less localized expression patterns.\n",
    "\n",
    "We don't see a clear variation due to randomization.\n",
    "\n",
    "Regarding correlation values, they all are much higher, above 0.9 or 0.95 for most cases. There is a more marked trend of higher corelation values up to $2\\sqrt{N}$, with a sudden drop in $5\\sqrt{N}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "df_violin_0_500 = compare_parameter(lib_prep, org, dataset, save_dir, 0, 500, what='overlap', by='pca')\n",
    "df_violin_0_1000 = compare_parameter(lib_prep, org, dataset, save_dir, 0, 1000, what='overlap', by='pca')\n",
    "df_violin_0_2500 = compare_parameter(lib_prep, org, dataset, save_dir, 0, 2500, what='overlap', by='pca')\n",
    "df_violin_0_5000 = compare_parameter(lib_prep, org, dataset, save_dir, 0, 5000, what='overlap', by='pca')\n",
    "\n",
    "# Remember: left = non randomized - right = randomized\n",
    "plot_scatter_parameter([df_violin_0_5000, df_violin_0_2500, df_violin_0_1000, df_violin_0_500], \n",
    "   ['0 - 5000',  '0 - 2500', '0 - 1000', '0 - 500'], \n",
    "    lib_prep, org, dataset, step=1, palette = 'sunsetmid4', by='pca',\n",
    "                       title='PCA_robustness,_overlap', \n",
    "    ylabel='Overlap', plot_random=plot_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_violin_0_500 = compare_parameter(lib_prep, org, dataset, save_dir, 0, 500, what='correlation', by='pca')\n",
    "df_violin_0_1000 = compare_parameter(lib_prep, org, dataset, save_dir, 0, 1000, what='correlation', by='pca')\n",
    "df_violin_0_2500 = compare_parameter(lib_prep, org, dataset, save_dir, 0, 2500, what='correlation', by='pca')\n",
    "df_violin_0_5000 = compare_parameter(lib_prep, org, dataset, save_dir, 0, 5000, what='correlation', by='pca')\n",
    "\n",
    "# Remember: left = non randomized - right = randomized\n",
    "plot_scatter_parameter([df_violin_0_5000, df_violin_0_2500, df_violin_0_1000, df_violin_0_500], \n",
    "   ['0 - 5000',  '0 - 2500', '0 - 1000', '0 - 500'], \n",
    "    lib_prep, org, dataset, step=1, \n",
    "    palette = 'sunsetmid4', by='pca', \n",
    "    title='PCA_robustness,_correlation', \n",
    "    ylabel='Pearson correlation', plot_random=plot_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we look at PCA component-based overlap, there is not a clear trend. Generally, overlap with cases of less than 20 components tend to be really different, and a number of components between 20 and 50 have similar overlap values.\n",
    "\n",
    "Again, library preparation methods that yield higher number of detected genes tend to score higher, which might be expected, because the *resolution* per gene will be better.\n",
    "\n",
    "We don't see a clear variation due to randomization.\n",
    "\n",
    "Correlation values are above 0.95 in all cases, regardless of dataset. The trends are the same as with overlap, but much marked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_violin_0_500 = compare_parameter(lib_prep, org, dataset, save_dir, 0, 500, what='overlap', by='w')\n",
    "df_violin_0_1000 = compare_parameter(lib_prep, org, dataset, save_dir, 0, 1000, what='overlap', by='w')\n",
    "df_violin_0_2500 = compare_parameter(lib_prep, org, dataset, save_dir, 0, 2500, what='overlap', by='w')\n",
    "df_violin_0_5000 = compare_parameter(lib_prep, org, dataset, save_dir, 0, 5000, what='overlap', by='w')\n",
    "\n",
    "# Remember: left = non randomized - right = randomized\n",
    "plot_scatter_parameter([df_violin_0_5000, df_violin_0_2500, df_violin_0_1000, df_violin_0_500], \n",
    "   ['0 - 5000',  '0 - 2500', '0 - 1000', '0 - 500'], \n",
    "    lib_prep, org, dataset, step=1, palette = 'sunsetmid4', by='w', title='window_robustness,_overlap', \n",
    "    ylabel='Overlap', plot_random=plot_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_violin_0_500 = compare_parameter(lib_prep, org, dataset, save_dir, 0, 500, what='correlation', by='w')\n",
    "df_violin_0_1000 = compare_parameter(lib_prep, org, dataset, save_dir, 0, 1000, what='correlation', by='w')\n",
    "df_violin_0_2500 = compare_parameter(lib_prep, org, dataset, save_dir, 0, 2500, what='correlation', by='w')\n",
    "df_violin_0_5000 = compare_parameter(lib_prep, org, dataset, save_dir, 0, 5000, what='correlation', by='w')\n",
    "\n",
    "# Remember: left = non randomized - right = randomized\n",
    "plot_scatter_parameter([df_violin_0_5000, df_violin_0_2500, df_violin_0_1000, df_violin_0_500], \n",
    "   ['0 - 5000',  '0 - 2500', '0 - 1000', '0 - 500'], \n",
    "    lib_prep, org, dataset, step=1, palette = 'sunsetmid4', by='w',\n",
    "    title='window_robustness,_correlation',\n",
    "    ylabel=\"Pearson correlation\", plot_random=plot_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Robustness on windows is really high. Overlap values are higher than 90%. Correlation values are much higher, above 0.99. There is a *symmetrical* decrease of over number of windows, which is expected as we saw on the `3_Why_applying_median_correction_is_a_good_option.ipynb` notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterate in all datasets!\n",
    "Since there are many datasets to iterate on, the same code used in the notebook is within `robustness_functions.py` so that it can be run in all datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "listdir = os.listdir(save_dir)\n",
    "for org in ['human', 'mouse']:\n",
    "    for lib_prep in ['SingleNuclei', 'inDrop', '10X', 'SMARTseq2', 'CELseq2', 'QUARTZseq', 'Dropseq', 'sci-RNAseq', 'Seq-Well',]:\n",
    "        for dataset in ['mereu', 'ding']:\n",
    "            matchfiles = [i for i in listdir if org in i and lib_prep in i and dataset in i]\n",
    "            if matchfiles:\n",
    "                print(org, dataset, lib_prep)\n",
    "                get_all_pics_dataset(lib_prep, org, dataset, save_dir, plot_random=plot_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of robustness across datasets\n",
    "In this section we are going to compare overlap values across kNN, PCA components and windows, using different datasets. To do that we are going to use three number of feature values (0-500 / 1000 / 2500) and plot for 1000 a line plot and a between_plot between 500 and 2500. The point that will be plotted will be the mean of overlaps between the different seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "what = 'overlap'\n",
    "low_val, mid_val, hi_val = 500, 1500, 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in ['mereu', 'ding']:\n",
    "    if dataset == 'mereu':\n",
    "        lib_preps = ['SingleNuclei', 'inDrop', '10X', 'SMARTseq2', 'CELseq2', 'QUARTZseq',]\n",
    "    else:\n",
    "        # Ding may fail because some libraries do not exist for mouse. I don't care\n",
    "        # because the most important results for PCA and kNN turn out right, and are \n",
    "        # the variables I care most for.\n",
    "        lib_preps = ['SingleNuclei', 'inDrop', '10X', 'SMARTseq2', 'CELseq2', 'Seq-Well',]\n",
    "    for org in ['human', 'mouse']:\n",
    "\n",
    "        list_dicts_dfs = [{}, {}, {}]\n",
    "        for lib_prep in lib_preps:\n",
    "            list_dicts_dfs[0][lib_prep] = compare_parameter(lib_prep, org, dataset, save_dir, 0, low_val, what=what, by='knn')\n",
    "            list_dicts_dfs[1][lib_prep] = compare_parameter(lib_prep, org, dataset, save_dir, 0, mid_val, what=what, by='knn')\n",
    "            list_dicts_dfs[2][lib_prep] = compare_parameter(lib_prep, org, dataset, save_dir, 0, hi_val, what=what, by='knn')\n",
    "\n",
    "        plot_scatter_datasets(list_dicts_dfs, org, by='knn', figsize=(7, 4),  palette='bold',\n",
    "                                   title=f'General_kNN_robustness_{dataset}_{org}', ylabel=what, \n",
    "                              save_dir=os.getcwd() + '/figures/robustness_figs')\n",
    "\n",
    "\n",
    "        list_dicts_dfs = [{}, {}, {}]\n",
    "        for lib_prep in lib_preps:\n",
    "            list_dicts_dfs[0][lib_prep] = compare_parameter(lib_prep, org, dataset, save_dir, 0, low_val, what=what, by='pca')\n",
    "            list_dicts_dfs[1][lib_prep] = compare_parameter(lib_prep, org, dataset, save_dir, 0, mid_val, what=what, by='pca')\n",
    "            list_dicts_dfs[2][lib_prep] = compare_parameter(lib_prep, org, dataset, save_dir, 0, hi_val, what=what, by='pca')\n",
    "\n",
    "        plot_scatter_datasets(list_dicts_dfs, org, by='pca', figsize=(7, 4),  palette='bold',\n",
    "                                   title=f'General_PCA_robustness_{dataset}_{org}', \n",
    "                              ylabel=what, save_dir=os.getcwd() + '/figures/robustness_figs')\n",
    "\n",
    "\n",
    "        list_dicts_dfs = [{}, {}, {}]\n",
    "        for lib_prep in lib_preps:\n",
    "            list_dicts_dfs[0][lib_prep] = compare_parameter(lib_prep, org, dataset, save_dir, 0, low_val, what=what, by='w')\n",
    "            list_dicts_dfs[1][lib_prep] = compare_parameter(lib_prep, org, dataset, save_dir, 0, mid_val, what=what, by='w')\n",
    "            list_dicts_dfs[2][lib_prep] = compare_parameter(lib_prep, org, dataset, save_dir, 0, hi_val, what=what, by='w')\n",
    "\n",
    "        plot_scatter_datasets(list_dicts_dfs, org, by='w', figsize=(7, 4),  palette='bold',\n",
    "                                   title=f'General_window_robustness_{dataset}_{org}', \n",
    "                              ylabel=what, save_dir=os.getcwd() + '/figures/robustness_figs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:alex-base] *",
   "language": "python",
   "name": "conda-env-alex-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "761px",
    "left": "45px",
    "top": "163.133px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
